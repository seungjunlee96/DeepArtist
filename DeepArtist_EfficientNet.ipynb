{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.applications import *\n",
    "from tensorflow.keras.callbacks import *\n",
    "from tensorflow.keras.initializers import *\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  4\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Vincent_van_Gogh', 'Edgar_Degas', 'Pablo_Picasso', 'Pierre-Auguste_Renoir', 'Albrecht_DuтХа├кrer', 'Paul_Gauguin', 'Francisco_Goya', 'Rembrandt', 'Alfred_Sisley', 'Titian', 'Marc_Chagall', 'Rene_Magritte', 'Amedeo_Modigliani', 'Paul_Klee', 'Henri_Matisse', 'Andy_Warhol', 'Mikhail_Vrubel', 'Sandro_Botticelli', 'Leonardo_da_Vinci', 'Peter_Paul_Rubens', 'Salvador_Dali', 'Hieronymus_Bosch', 'Pieter_Bruegel', 'Diego_Velazquez', 'Kazimir_Malevich', 'Giotto_di_Bondone', 'Frida_Kahlo', 'Gustav_Klimt', 'Raphael', 'Joan_Miro', 'Andrei_Rublev', 'Camille_Pissarro', 'Edouard_Manet', 'Vasiliy_Kandinskiy', 'El_Greco', 'Piet_Mondrian', 'Henri_de_Toulouse-Lautrec', 'Jan_van_Eyck', 'Claude_Monet', 'Henri_Rousseau', 'Diego_Rivera', 'Edvard_Munch', 'William_Turner', 'Gustave_Courbet', 'Caravaggio', 'Michelangelo', 'Paul_Cezanne', 'Georges_Seurat', 'Eugene_Delacroix', 'Jackson_Pollock']\n"
     ]
    }
   ],
   "source": [
    "# Dataset Loading\n",
    "train_dir = './data/best-artworks-of-all-time/images/images/'\n",
    "test_dir = './data/best-artworks-of-all-time/images/testset/'\n",
    "\n",
    "artist_names = os.listdir(train_dir)\n",
    "\n",
    "artists = dict()\n",
    "CLASS_WEIGHT = dict()\n",
    "\n",
    "for artist_name in artist_names:\n",
    "    artists[artist_name] = len(os.listdir(train_dir + artist_name))\n",
    "artists = {k: v for k, v in sorted(artists.items(), key=lambda item: item[1] , reverse = True)}\n",
    "\n",
    "for i , artist_name in enumerate(artists.keys()):\n",
    "    CLASS_WEIGHT[i] =  max(artists.values())/artists[artist_name]\n",
    "    artist_names[i] = artist_name\n",
    "\n",
    "\n",
    "#sum(artists.values())/len(artists) # 예술가의 평균 그림 갯수\n",
    "#CLASS_WEIGHT\n",
    "print(artist_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "Found 6862 images belonging to 50 classes.\n",
      "Found 1186 images belonging to 50 classes.\n",
      "Found 398 images belonging to 50 classes.\n",
      "Total number of batches = 428 and 74\n"
     ]
    }
   ],
   "source": [
    "# Configure the ImageDataGenerator\n",
    "batch_size = 16 #increased batchsize from 32 to 128 \n",
    "train_input_shape = (600, 600 , 3) # input shape for EfficientNet B-7\n",
    "n_classes = len(artists)\n",
    "\n",
    "my_strategy = tf.distribute.MirroredStrategy()\n",
    "with my_strategy.scope():\n",
    "\n",
    "\n",
    "    #Define Data Augmentation\n",
    "    train_datagen = ImageDataGenerator(validation_split=0.15,\n",
    "                                       rescale = 1./255.,   \n",
    "                                       #featurewise_center = True,\n",
    "                                       #featurewise_std_normalization = True\n",
    "                                       #samplewise_center= True,\n",
    "                                       #samplewise_std_normalization=True,\n",
    "                                       zca_epsilon=1e-6,\n",
    "                                       #zca_whitening = True,\n",
    "                                       rotation_range=30,\n",
    "                                       width_shift_range=0.3,\n",
    "                                       height_shift_range=0.3,\n",
    "                                       brightness_range = [0.7 , 1.3], #Tuple of floats; range to pick a brightness value from.\n",
    "                                       shear_range=0.3,\n",
    "                                       zoom_range=0.7, # zoom range = [1-zoom_range , 1 + zoom_range]\n",
    "                                       channel_shift_range = 100,\n",
    "                                       horizontal_flip=True,\n",
    "                                       vertical_flip=True,\n",
    "                                       fill_mode = 'nearest' )\n",
    "    #Fit the augmentation\n",
    "    #train_datagen.fit()\n",
    "    \n",
    "    test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(directory= train_dir,\n",
    "                                                        class_mode='categorical',\n",
    "                                                        target_size=train_input_shape[0:2],\n",
    "                                                        batch_size=batch_size,\n",
    "                                                        subset=\"training\",\n",
    "                                                        shuffle=True,\n",
    "                                                        classes=artist_names\n",
    "                                                       )\n",
    "\n",
    "    valid_generator = train_datagen.flow_from_directory(directory= train_dir,\n",
    "                                                        class_mode='categorical',\n",
    "                                                        target_size=train_input_shape[0:2],\n",
    "                                                        batch_size=batch_size,\n",
    "                                                        subset=\"validation\",\n",
    "                                                        shuffle=True,\n",
    "                                                        classes=artist_names)\n",
    "    \n",
    "    test_generator = test_datagen.flow_from_directory(directory = test_dir,\n",
    "                                                      class_mode = 'categorical',\n",
    "                                                      target_size = train_input_shape[0:2],\n",
    "                                                      batch_size = 1,\n",
    "                                                      classes = artist_names)\n",
    "    \n",
    "    STEP_SIZE_TRAIN = train_generator.n//train_generator.batch_size\n",
    "    STEP_SIZE_VALID = valid_generator.n//valid_generator.batch_size\n",
    "    print(\"Total number of batches =\", STEP_SIZE_TRAIN, \"and\", STEP_SIZE_VALID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1,os.getcwd())\n",
    "\n",
    "from keras__applications.keras_applications.efficientnet import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"efficientnet-b7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 600, 600, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "stem_conv_pad (ZeroPadding2D)   (None, 601, 601, 3)  0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "stem_conv (Conv2D)              (None, 300, 300, 64) 1728        stem_conv_pad[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stem_bn (BatchNormalization)    (None, 300, 300, 64) 256         stem_conv[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "stem_activation (Activation)    (None, 300, 300, 64) 0           stem_bn[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1a_dwconv (DepthwiseConv2D (None, 300, 300, 64) 576         stem_activation[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1a_bn (BatchNormalization) (None, 300, 300, 64) 256         block1a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block1a_activation (Activation) (None, 300, 300, 64) 0           block1a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_squeeze (GlobalAvera (None, 64)           0           block1a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_reshape (Reshape)    (None, 1, 1, 64)     0           block1a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_reduce (Conv2D)      (None, 1, 1, 16)     1040        block1a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_expand (Conv2D)      (None, 1, 1, 64)     1088        block1a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_excite (Multiply)    (None, 300, 300, 64) 0           block1a_activation[0][0]         \n",
      "                                                                 block1a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1a_project_conv (Conv2D)   (None, 300, 300, 32) 2048        block1a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1a_project_bn (BatchNormal (None, 300, 300, 32) 128         block1a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block1b_dwconv (DepthwiseConv2D (None, 300, 300, 32) 288         block1a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1b_bn (BatchNormalization) (None, 300, 300, 32) 128         block1b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block1b_activation (Activation) (None, 300, 300, 32) 0           block1b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block1b_se_squeeze (GlobalAvera (None, 32)           0           block1b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1b_se_reshape (Reshape)    (None, 1, 1, 32)     0           block1b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1b_se_reduce (Conv2D)      (None, 1, 1, 8)      264         block1b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1b_se_expand (Conv2D)      (None, 1, 1, 32)     288         block1b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1b_se_excite (Multiply)    (None, 300, 300, 32) 0           block1b_activation[0][0]         \n",
      "                                                                 block1b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1b_project_conv (Conv2D)   (None, 300, 300, 32) 1024        block1b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1b_project_bn (BatchNormal (None, 300, 300, 32) 128         block1b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block1b_drop (Dropout)          (None, 300, 300, 32) 0           block1b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1b_add (Add)               (None, 300, 300, 32) 0           block1b_drop[0][0]               \n",
      "                                                                 block1a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1c_dwconv (DepthwiseConv2D (None, 300, 300, 32) 288         block1b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block1c_bn (BatchNormalization) (None, 300, 300, 32) 128         block1c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block1c_activation (Activation) (None, 300, 300, 32) 0           block1c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block1c_se_squeeze (GlobalAvera (None, 32)           0           block1c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1c_se_reshape (Reshape)    (None, 1, 1, 32)     0           block1c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1c_se_reduce (Conv2D)      (None, 1, 1, 8)      264         block1c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1c_se_expand (Conv2D)      (None, 1, 1, 32)     288         block1c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1c_se_excite (Multiply)    (None, 300, 300, 32) 0           block1c_activation[0][0]         \n",
      "                                                                 block1c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1c_project_conv (Conv2D)   (None, 300, 300, 32) 1024        block1c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1c_project_bn (BatchNormal (None, 300, 300, 32) 128         block1c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block1c_drop (Dropout)          (None, 300, 300, 32) 0           block1c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1c_add (Add)               (None, 300, 300, 32) 0           block1c_drop[0][0]               \n",
      "                                                                 block1b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block1d_dwconv (DepthwiseConv2D (None, 300, 300, 32) 288         block1c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block1d_bn (BatchNormalization) (None, 300, 300, 32) 128         block1d_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block1d_activation (Activation) (None, 300, 300, 32) 0           block1d_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block1d_se_squeeze (GlobalAvera (None, 32)           0           block1d_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1d_se_reshape (Reshape)    (None, 1, 1, 32)     0           block1d_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1d_se_reduce (Conv2D)      (None, 1, 1, 8)      264         block1d_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1d_se_expand (Conv2D)      (None, 1, 1, 32)     288         block1d_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1d_se_excite (Multiply)    (None, 300, 300, 32) 0           block1d_activation[0][0]         \n",
      "                                                                 block1d_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1d_project_conv (Conv2D)   (None, 300, 300, 32) 1024        block1d_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1d_project_bn (BatchNormal (None, 300, 300, 32) 128         block1d_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block1d_drop (Dropout)          (None, 300, 300, 32) 0           block1d_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1d_add (Add)               (None, 300, 300, 32) 0           block1d_drop[0][0]               \n",
      "                                                                 block1c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2a_expand_conv (Conv2D)    (None, 300, 300, 192 6144        block1d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2a_expand_bn (BatchNormali (None, 300, 300, 192 768         block2a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2a_expand_activation (Acti (None, 300, 300, 192 0           block2a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_dwconv_pad (ZeroPadding (None, 301, 301, 192 0           block2a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2a_dwconv (DepthwiseConv2D (None, 150, 150, 192 1728        block2a_dwconv_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_bn (BatchNormalization) (None, 150, 150, 192 768         block2a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2a_activation (Activation) (None, 150, 150, 192 0           block2a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_squeeze (GlobalAvera (None, 192)          0           block2a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_reshape (Reshape)    (None, 1, 1, 192)    0           block2a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_reduce (Conv2D)      (None, 1, 1, 8)      1544        block2a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_expand (Conv2D)      (None, 1, 1, 192)    1728        block2a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_excite (Multiply)    (None, 150, 150, 192 0           block2a_activation[0][0]         \n",
      "                                                                 block2a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_project_conv (Conv2D)   (None, 150, 150, 48) 9216        block2a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_project_bn (BatchNormal (None, 150, 150, 48) 192         block2a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2b_expand_conv (Conv2D)    (None, 150, 150, 288 13824       block2a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_expand_bn (BatchNormali (None, 150, 150, 288 1152        block2b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2b_expand_activation (Acti (None, 150, 150, 288 0           block2b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_dwconv (DepthwiseConv2D (None, 150, 150, 288 2592        block2b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2b_bn (BatchNormalization) (None, 150, 150, 288 1152        block2b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2b_activation (Activation) (None, 150, 150, 288 0           block2b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_squeeze (GlobalAvera (None, 288)          0           block2b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_reshape (Reshape)    (None, 1, 1, 288)    0           block2b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_reduce (Conv2D)      (None, 1, 1, 12)     3468        block2b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_expand (Conv2D)      (None, 1, 1, 288)    3744        block2b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_excite (Multiply)    (None, 150, 150, 288 0           block2b_activation[0][0]         \n",
      "                                                                 block2b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_project_conv (Conv2D)   (None, 150, 150, 48) 13824       block2b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_project_bn (BatchNormal (None, 150, 150, 48) 192         block2b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2b_drop (Dropout)          (None, 150, 150, 48) 0           block2b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_add (Add)               (None, 150, 150, 48) 0           block2b_drop[0][0]               \n",
      "                                                                 block2a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2c_expand_conv (Conv2D)    (None, 150, 150, 288 13824       block2b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2c_expand_bn (BatchNormali (None, 150, 150, 288 1152        block2c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2c_expand_activation (Acti (None, 150, 150, 288 0           block2c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2c_dwconv (DepthwiseConv2D (None, 150, 150, 288 2592        block2c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2c_bn (BatchNormalization) (None, 150, 150, 288 1152        block2c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2c_activation (Activation) (None, 150, 150, 288 0           block2c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2c_se_squeeze (GlobalAvera (None, 288)          0           block2c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2c_se_reshape (Reshape)    (None, 1, 1, 288)    0           block2c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2c_se_reduce (Conv2D)      (None, 1, 1, 12)     3468        block2c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2c_se_expand (Conv2D)      (None, 1, 1, 288)    3744        block2c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2c_se_excite (Multiply)    (None, 150, 150, 288 0           block2c_activation[0][0]         \n",
      "                                                                 block2c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2c_project_conv (Conv2D)   (None, 150, 150, 48) 13824       block2c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2c_project_bn (BatchNormal (None, 150, 150, 48) 192         block2c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2c_drop (Dropout)          (None, 150, 150, 48) 0           block2c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2c_add (Add)               (None, 150, 150, 48) 0           block2c_drop[0][0]               \n",
      "                                                                 block2b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2d_expand_conv (Conv2D)    (None, 150, 150, 288 13824       block2c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2d_expand_bn (BatchNormali (None, 150, 150, 288 1152        block2d_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2d_expand_activation (Acti (None, 150, 150, 288 0           block2d_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2d_dwconv (DepthwiseConv2D (None, 150, 150, 288 2592        block2d_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2d_bn (BatchNormalization) (None, 150, 150, 288 1152        block2d_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2d_activation (Activation) (None, 150, 150, 288 0           block2d_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2d_se_squeeze (GlobalAvera (None, 288)          0           block2d_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2d_se_reshape (Reshape)    (None, 1, 1, 288)    0           block2d_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2d_se_reduce (Conv2D)      (None, 1, 1, 12)     3468        block2d_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2d_se_expand (Conv2D)      (None, 1, 1, 288)    3744        block2d_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2d_se_excite (Multiply)    (None, 150, 150, 288 0           block2d_activation[0][0]         \n",
      "                                                                 block2d_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2d_project_conv (Conv2D)   (None, 150, 150, 48) 13824       block2d_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2d_project_bn (BatchNormal (None, 150, 150, 48) 192         block2d_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2d_drop (Dropout)          (None, 150, 150, 48) 0           block2d_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2d_add (Add)               (None, 150, 150, 48) 0           block2d_drop[0][0]               \n",
      "                                                                 block2c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2e_expand_conv (Conv2D)    (None, 150, 150, 288 13824       block2d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2e_expand_bn (BatchNormali (None, 150, 150, 288 1152        block2e_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2e_expand_activation (Acti (None, 150, 150, 288 0           block2e_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2e_dwconv (DepthwiseConv2D (None, 150, 150, 288 2592        block2e_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2e_bn (BatchNormalization) (None, 150, 150, 288 1152        block2e_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2e_activation (Activation) (None, 150, 150, 288 0           block2e_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2e_se_squeeze (GlobalAvera (None, 288)          0           block2e_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2e_se_reshape (Reshape)    (None, 1, 1, 288)    0           block2e_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2e_se_reduce (Conv2D)      (None, 1, 1, 12)     3468        block2e_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2e_se_expand (Conv2D)      (None, 1, 1, 288)    3744        block2e_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2e_se_excite (Multiply)    (None, 150, 150, 288 0           block2e_activation[0][0]         \n",
      "                                                                 block2e_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2e_project_conv (Conv2D)   (None, 150, 150, 48) 13824       block2e_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2e_project_bn (BatchNormal (None, 150, 150, 48) 192         block2e_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2e_drop (Dropout)          (None, 150, 150, 48) 0           block2e_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2e_add (Add)               (None, 150, 150, 48) 0           block2e_drop[0][0]               \n",
      "                                                                 block2d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2f_expand_conv (Conv2D)    (None, 150, 150, 288 13824       block2e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2f_expand_bn (BatchNormali (None, 150, 150, 288 1152        block2f_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2f_expand_activation (Acti (None, 150, 150, 288 0           block2f_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2f_dwconv (DepthwiseConv2D (None, 150, 150, 288 2592        block2f_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2f_bn (BatchNormalization) (None, 150, 150, 288 1152        block2f_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2f_activation (Activation) (None, 150, 150, 288 0           block2f_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2f_se_squeeze (GlobalAvera (None, 288)          0           block2f_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2f_se_reshape (Reshape)    (None, 1, 1, 288)    0           block2f_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2f_se_reduce (Conv2D)      (None, 1, 1, 12)     3468        block2f_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2f_se_expand (Conv2D)      (None, 1, 1, 288)    3744        block2f_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2f_se_excite (Multiply)    (None, 150, 150, 288 0           block2f_activation[0][0]         \n",
      "                                                                 block2f_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2f_project_conv (Conv2D)   (None, 150, 150, 48) 13824       block2f_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2f_project_bn (BatchNormal (None, 150, 150, 48) 192         block2f_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2f_drop (Dropout)          (None, 150, 150, 48) 0           block2f_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2f_add (Add)               (None, 150, 150, 48) 0           block2f_drop[0][0]               \n",
      "                                                                 block2e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2g_expand_conv (Conv2D)    (None, 150, 150, 288 13824       block2f_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2g_expand_bn (BatchNormali (None, 150, 150, 288 1152        block2g_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2g_expand_activation (Acti (None, 150, 150, 288 0           block2g_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2g_dwconv (DepthwiseConv2D (None, 150, 150, 288 2592        block2g_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2g_bn (BatchNormalization) (None, 150, 150, 288 1152        block2g_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2g_activation (Activation) (None, 150, 150, 288 0           block2g_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2g_se_squeeze (GlobalAvera (None, 288)          0           block2g_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2g_se_reshape (Reshape)    (None, 1, 1, 288)    0           block2g_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2g_se_reduce (Conv2D)      (None, 1, 1, 12)     3468        block2g_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2g_se_expand (Conv2D)      (None, 1, 1, 288)    3744        block2g_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2g_se_excite (Multiply)    (None, 150, 150, 288 0           block2g_activation[0][0]         \n",
      "                                                                 block2g_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2g_project_conv (Conv2D)   (None, 150, 150, 48) 13824       block2g_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2g_project_bn (BatchNormal (None, 150, 150, 48) 192         block2g_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2g_drop (Dropout)          (None, 150, 150, 48) 0           block2g_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2g_add (Add)               (None, 150, 150, 48) 0           block2g_drop[0][0]               \n",
      "                                                                 block2f_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3a_expand_conv (Conv2D)    (None, 150, 150, 288 13824       block2g_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3a_expand_bn (BatchNormali (None, 150, 150, 288 1152        block3a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3a_expand_activation (Acti (None, 150, 150, 288 0           block3a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_dwconv_pad (ZeroPadding (None, 153, 153, 288 0           block3a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3a_dwconv (DepthwiseConv2D (None, 75, 75, 288)  7200        block3a_dwconv_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_bn (BatchNormalization) (None, 75, 75, 288)  1152        block3a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3a_activation (Activation) (None, 75, 75, 288)  0           block3a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_squeeze (GlobalAvera (None, 288)          0           block3a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_reshape (Reshape)    (None, 1, 1, 288)    0           block3a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_reduce (Conv2D)      (None, 1, 1, 12)     3468        block3a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_expand (Conv2D)      (None, 1, 1, 288)    3744        block3a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_excite (Multiply)    (None, 75, 75, 288)  0           block3a_activation[0][0]         \n",
      "                                                                 block3a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_project_conv (Conv2D)   (None, 75, 75, 80)   23040       block3a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_project_bn (BatchNormal (None, 75, 75, 80)   320         block3a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3b_expand_conv (Conv2D)    (None, 75, 75, 480)  38400       block3a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_expand_bn (BatchNormali (None, 75, 75, 480)  1920        block3b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3b_expand_activation (Acti (None, 75, 75, 480)  0           block3b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_dwconv (DepthwiseConv2D (None, 75, 75, 480)  12000       block3b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3b_bn (BatchNormalization) (None, 75, 75, 480)  1920        block3b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3b_activation (Activation) (None, 75, 75, 480)  0           block3b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_squeeze (GlobalAvera (None, 480)          0           block3b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_reshape (Reshape)    (None, 1, 1, 480)    0           block3b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_reduce (Conv2D)      (None, 1, 1, 20)     9620        block3b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_expand (Conv2D)      (None, 1, 1, 480)    10080       block3b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_excite (Multiply)    (None, 75, 75, 480)  0           block3b_activation[0][0]         \n",
      "                                                                 block3b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_project_conv (Conv2D)   (None, 75, 75, 80)   38400       block3b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_project_bn (BatchNormal (None, 75, 75, 80)   320         block3b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3b_drop (Dropout)          (None, 75, 75, 80)   0           block3b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_add (Add)               (None, 75, 75, 80)   0           block3b_drop[0][0]               \n",
      "                                                                 block3a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3c_expand_conv (Conv2D)    (None, 75, 75, 480)  38400       block3b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3c_expand_bn (BatchNormali (None, 75, 75, 480)  1920        block3c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3c_expand_activation (Acti (None, 75, 75, 480)  0           block3c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3c_dwconv (DepthwiseConv2D (None, 75, 75, 480)  12000       block3c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3c_bn (BatchNormalization) (None, 75, 75, 480)  1920        block3c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3c_activation (Activation) (None, 75, 75, 480)  0           block3c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3c_se_squeeze (GlobalAvera (None, 480)          0           block3c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3c_se_reshape (Reshape)    (None, 1, 1, 480)    0           block3c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3c_se_reduce (Conv2D)      (None, 1, 1, 20)     9620        block3c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3c_se_expand (Conv2D)      (None, 1, 1, 480)    10080       block3c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3c_se_excite (Multiply)    (None, 75, 75, 480)  0           block3c_activation[0][0]         \n",
      "                                                                 block3c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3c_project_conv (Conv2D)   (None, 75, 75, 80)   38400       block3c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3c_project_bn (BatchNormal (None, 75, 75, 80)   320         block3c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3c_drop (Dropout)          (None, 75, 75, 80)   0           block3c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3c_add (Add)               (None, 75, 75, 80)   0           block3c_drop[0][0]               \n",
      "                                                                 block3b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3d_expand_conv (Conv2D)    (None, 75, 75, 480)  38400       block3c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3d_expand_bn (BatchNormali (None, 75, 75, 480)  1920        block3d_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3d_expand_activation (Acti (None, 75, 75, 480)  0           block3d_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3d_dwconv (DepthwiseConv2D (None, 75, 75, 480)  12000       block3d_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3d_bn (BatchNormalization) (None, 75, 75, 480)  1920        block3d_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3d_activation (Activation) (None, 75, 75, 480)  0           block3d_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3d_se_squeeze (GlobalAvera (None, 480)          0           block3d_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3d_se_reshape (Reshape)    (None, 1, 1, 480)    0           block3d_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3d_se_reduce (Conv2D)      (None, 1, 1, 20)     9620        block3d_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3d_se_expand (Conv2D)      (None, 1, 1, 480)    10080       block3d_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3d_se_excite (Multiply)    (None, 75, 75, 480)  0           block3d_activation[0][0]         \n",
      "                                                                 block3d_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3d_project_conv (Conv2D)   (None, 75, 75, 80)   38400       block3d_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3d_project_bn (BatchNormal (None, 75, 75, 80)   320         block3d_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3d_drop (Dropout)          (None, 75, 75, 80)   0           block3d_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3d_add (Add)               (None, 75, 75, 80)   0           block3d_drop[0][0]               \n",
      "                                                                 block3c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3e_expand_conv (Conv2D)    (None, 75, 75, 480)  38400       block3d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3e_expand_bn (BatchNormali (None, 75, 75, 480)  1920        block3e_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3e_expand_activation (Acti (None, 75, 75, 480)  0           block3e_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3e_dwconv (DepthwiseConv2D (None, 75, 75, 480)  12000       block3e_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3e_bn (BatchNormalization) (None, 75, 75, 480)  1920        block3e_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3e_activation (Activation) (None, 75, 75, 480)  0           block3e_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3e_se_squeeze (GlobalAvera (None, 480)          0           block3e_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3e_se_reshape (Reshape)    (None, 1, 1, 480)    0           block3e_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3e_se_reduce (Conv2D)      (None, 1, 1, 20)     9620        block3e_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3e_se_expand (Conv2D)      (None, 1, 1, 480)    10080       block3e_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3e_se_excite (Multiply)    (None, 75, 75, 480)  0           block3e_activation[0][0]         \n",
      "                                                                 block3e_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3e_project_conv (Conv2D)   (None, 75, 75, 80)   38400       block3e_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3e_project_bn (BatchNormal (None, 75, 75, 80)   320         block3e_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3e_drop (Dropout)          (None, 75, 75, 80)   0           block3e_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3e_add (Add)               (None, 75, 75, 80)   0           block3e_drop[0][0]               \n",
      "                                                                 block3d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3f_expand_conv (Conv2D)    (None, 75, 75, 480)  38400       block3e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3f_expand_bn (BatchNormali (None, 75, 75, 480)  1920        block3f_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3f_expand_activation (Acti (None, 75, 75, 480)  0           block3f_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3f_dwconv (DepthwiseConv2D (None, 75, 75, 480)  12000       block3f_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3f_bn (BatchNormalization) (None, 75, 75, 480)  1920        block3f_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3f_activation (Activation) (None, 75, 75, 480)  0           block3f_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3f_se_squeeze (GlobalAvera (None, 480)          0           block3f_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3f_se_reshape (Reshape)    (None, 1, 1, 480)    0           block3f_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3f_se_reduce (Conv2D)      (None, 1, 1, 20)     9620        block3f_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3f_se_expand (Conv2D)      (None, 1, 1, 480)    10080       block3f_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3f_se_excite (Multiply)    (None, 75, 75, 480)  0           block3f_activation[0][0]         \n",
      "                                                                 block3f_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3f_project_conv (Conv2D)   (None, 75, 75, 80)   38400       block3f_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3f_project_bn (BatchNormal (None, 75, 75, 80)   320         block3f_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3f_drop (Dropout)          (None, 75, 75, 80)   0           block3f_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3f_add (Add)               (None, 75, 75, 80)   0           block3f_drop[0][0]               \n",
      "                                                                 block3e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3g_expand_conv (Conv2D)    (None, 75, 75, 480)  38400       block3f_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3g_expand_bn (BatchNormali (None, 75, 75, 480)  1920        block3g_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3g_expand_activation (Acti (None, 75, 75, 480)  0           block3g_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3g_dwconv (DepthwiseConv2D (None, 75, 75, 480)  12000       block3g_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3g_bn (BatchNormalization) (None, 75, 75, 480)  1920        block3g_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3g_activation (Activation) (None, 75, 75, 480)  0           block3g_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3g_se_squeeze (GlobalAvera (None, 480)          0           block3g_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3g_se_reshape (Reshape)    (None, 1, 1, 480)    0           block3g_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3g_se_reduce (Conv2D)      (None, 1, 1, 20)     9620        block3g_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3g_se_expand (Conv2D)      (None, 1, 1, 480)    10080       block3g_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3g_se_excite (Multiply)    (None, 75, 75, 480)  0           block3g_activation[0][0]         \n",
      "                                                                 block3g_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3g_project_conv (Conv2D)   (None, 75, 75, 80)   38400       block3g_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3g_project_bn (BatchNormal (None, 75, 75, 80)   320         block3g_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3g_drop (Dropout)          (None, 75, 75, 80)   0           block3g_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3g_add (Add)               (None, 75, 75, 80)   0           block3g_drop[0][0]               \n",
      "                                                                 block3f_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4a_expand_conv (Conv2D)    (None, 75, 75, 480)  38400       block3g_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4a_expand_bn (BatchNormali (None, 75, 75, 480)  1920        block4a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4a_expand_activation (Acti (None, 75, 75, 480)  0           block4a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_dwconv_pad (ZeroPadding (None, 77, 77, 480)  0           block4a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4a_dwconv (DepthwiseConv2D (None, 38, 38, 480)  4320        block4a_dwconv_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_bn (BatchNormalization) (None, 38, 38, 480)  1920        block4a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4a_activation (Activation) (None, 38, 38, 480)  0           block4a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_squeeze (GlobalAvera (None, 480)          0           block4a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_reshape (Reshape)    (None, 1, 1, 480)    0           block4a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_reduce (Conv2D)      (None, 1, 1, 20)     9620        block4a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_expand (Conv2D)      (None, 1, 1, 480)    10080       block4a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_excite (Multiply)    (None, 38, 38, 480)  0           block4a_activation[0][0]         \n",
      "                                                                 block4a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_project_conv (Conv2D)   (None, 38, 38, 160)  76800       block4a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_project_bn (BatchNormal (None, 38, 38, 160)  640         block4a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4b_expand_conv (Conv2D)    (None, 38, 38, 960)  153600      block4a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_expand_bn (BatchNormali (None, 38, 38, 960)  3840        block4b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4b_expand_activation (Acti (None, 38, 38, 960)  0           block4b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_dwconv (DepthwiseConv2D (None, 38, 38, 960)  8640        block4b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4b_bn (BatchNormalization) (None, 38, 38, 960)  3840        block4b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4b_activation (Activation) (None, 38, 38, 960)  0           block4b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_squeeze (GlobalAvera (None, 960)          0           block4b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_reshape (Reshape)    (None, 1, 1, 960)    0           block4b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_reduce (Conv2D)      (None, 1, 1, 40)     38440       block4b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_expand (Conv2D)      (None, 1, 1, 960)    39360       block4b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_excite (Multiply)    (None, 38, 38, 960)  0           block4b_activation[0][0]         \n",
      "                                                                 block4b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_project_conv (Conv2D)   (None, 38, 38, 160)  153600      block4b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_project_bn (BatchNormal (None, 38, 38, 160)  640         block4b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4b_drop (Dropout)          (None, 38, 38, 160)  0           block4b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_add (Add)               (None, 38, 38, 160)  0           block4b_drop[0][0]               \n",
      "                                                                 block4a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_expand_conv (Conv2D)    (None, 38, 38, 960)  153600      block4b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4c_expand_bn (BatchNormali (None, 38, 38, 960)  3840        block4c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4c_expand_activation (Acti (None, 38, 38, 960)  0           block4c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_dwconv (DepthwiseConv2D (None, 38, 38, 960)  8640        block4c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4c_bn (BatchNormalization) (None, 38, 38, 960)  3840        block4c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4c_activation (Activation) (None, 38, 38, 960)  0           block4c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_squeeze (GlobalAvera (None, 960)          0           block4c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_reshape (Reshape)    (None, 1, 1, 960)    0           block4c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_reduce (Conv2D)      (None, 1, 1, 40)     38440       block4c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_expand (Conv2D)      (None, 1, 1, 960)    39360       block4c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_excite (Multiply)    (None, 38, 38, 960)  0           block4c_activation[0][0]         \n",
      "                                                                 block4c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_project_conv (Conv2D)   (None, 38, 38, 160)  153600      block4c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_project_bn (BatchNormal (None, 38, 38, 160)  640         block4c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4c_drop (Dropout)          (None, 38, 38, 160)  0           block4c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_add (Add)               (None, 38, 38, 160)  0           block4c_drop[0][0]               \n",
      "                                                                 block4b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4d_expand_conv (Conv2D)    (None, 38, 38, 960)  153600      block4c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4d_expand_bn (BatchNormali (None, 38, 38, 960)  3840        block4d_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4d_expand_activation (Acti (None, 38, 38, 960)  0           block4d_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4d_dwconv (DepthwiseConv2D (None, 38, 38, 960)  8640        block4d_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4d_bn (BatchNormalization) (None, 38, 38, 960)  3840        block4d_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4d_activation (Activation) (None, 38, 38, 960)  0           block4d_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4d_se_squeeze (GlobalAvera (None, 960)          0           block4d_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4d_se_reshape (Reshape)    (None, 1, 1, 960)    0           block4d_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4d_se_reduce (Conv2D)      (None, 1, 1, 40)     38440       block4d_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4d_se_expand (Conv2D)      (None, 1, 1, 960)    39360       block4d_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4d_se_excite (Multiply)    (None, 38, 38, 960)  0           block4d_activation[0][0]         \n",
      "                                                                 block4d_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4d_project_conv (Conv2D)   (None, 38, 38, 160)  153600      block4d_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4d_project_bn (BatchNormal (None, 38, 38, 160)  640         block4d_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4d_drop (Dropout)          (None, 38, 38, 160)  0           block4d_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4d_add (Add)               (None, 38, 38, 160)  0           block4d_drop[0][0]               \n",
      "                                                                 block4c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4e_expand_conv (Conv2D)    (None, 38, 38, 960)  153600      block4d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4e_expand_bn (BatchNormali (None, 38, 38, 960)  3840        block4e_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4e_expand_activation (Acti (None, 38, 38, 960)  0           block4e_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4e_dwconv (DepthwiseConv2D (None, 38, 38, 960)  8640        block4e_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4e_bn (BatchNormalization) (None, 38, 38, 960)  3840        block4e_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4e_activation (Activation) (None, 38, 38, 960)  0           block4e_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4e_se_squeeze (GlobalAvera (None, 960)          0           block4e_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4e_se_reshape (Reshape)    (None, 1, 1, 960)    0           block4e_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4e_se_reduce (Conv2D)      (None, 1, 1, 40)     38440       block4e_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4e_se_expand (Conv2D)      (None, 1, 1, 960)    39360       block4e_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4e_se_excite (Multiply)    (None, 38, 38, 960)  0           block4e_activation[0][0]         \n",
      "                                                                 block4e_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4e_project_conv (Conv2D)   (None, 38, 38, 160)  153600      block4e_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4e_project_bn (BatchNormal (None, 38, 38, 160)  640         block4e_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4e_drop (Dropout)          (None, 38, 38, 160)  0           block4e_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4e_add (Add)               (None, 38, 38, 160)  0           block4e_drop[0][0]               \n",
      "                                                                 block4d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4f_expand_conv (Conv2D)    (None, 38, 38, 960)  153600      block4e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4f_expand_bn (BatchNormali (None, 38, 38, 960)  3840        block4f_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4f_expand_activation (Acti (None, 38, 38, 960)  0           block4f_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4f_dwconv (DepthwiseConv2D (None, 38, 38, 960)  8640        block4f_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4f_bn (BatchNormalization) (None, 38, 38, 960)  3840        block4f_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4f_activation (Activation) (None, 38, 38, 960)  0           block4f_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4f_se_squeeze (GlobalAvera (None, 960)          0           block4f_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4f_se_reshape (Reshape)    (None, 1, 1, 960)    0           block4f_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4f_se_reduce (Conv2D)      (None, 1, 1, 40)     38440       block4f_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4f_se_expand (Conv2D)      (None, 1, 1, 960)    39360       block4f_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4f_se_excite (Multiply)    (None, 38, 38, 960)  0           block4f_activation[0][0]         \n",
      "                                                                 block4f_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4f_project_conv (Conv2D)   (None, 38, 38, 160)  153600      block4f_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4f_project_bn (BatchNormal (None, 38, 38, 160)  640         block4f_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4f_drop (Dropout)          (None, 38, 38, 160)  0           block4f_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4f_add (Add)               (None, 38, 38, 160)  0           block4f_drop[0][0]               \n",
      "                                                                 block4e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4g_expand_conv (Conv2D)    (None, 38, 38, 960)  153600      block4f_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4g_expand_bn (BatchNormali (None, 38, 38, 960)  3840        block4g_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4g_expand_activation (Acti (None, 38, 38, 960)  0           block4g_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4g_dwconv (DepthwiseConv2D (None, 38, 38, 960)  8640        block4g_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4g_bn (BatchNormalization) (None, 38, 38, 960)  3840        block4g_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4g_activation (Activation) (None, 38, 38, 960)  0           block4g_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4g_se_squeeze (GlobalAvera (None, 960)          0           block4g_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4g_se_reshape (Reshape)    (None, 1, 1, 960)    0           block4g_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4g_se_reduce (Conv2D)      (None, 1, 1, 40)     38440       block4g_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4g_se_expand (Conv2D)      (None, 1, 1, 960)    39360       block4g_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4g_se_excite (Multiply)    (None, 38, 38, 960)  0           block4g_activation[0][0]         \n",
      "                                                                 block4g_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4g_project_conv (Conv2D)   (None, 38, 38, 160)  153600      block4g_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4g_project_bn (BatchNormal (None, 38, 38, 160)  640         block4g_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4g_drop (Dropout)          (None, 38, 38, 160)  0           block4g_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4g_add (Add)               (None, 38, 38, 160)  0           block4g_drop[0][0]               \n",
      "                                                                 block4f_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4h_expand_conv (Conv2D)    (None, 38, 38, 960)  153600      block4g_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4h_expand_bn (BatchNormali (None, 38, 38, 960)  3840        block4h_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4h_expand_activation (Acti (None, 38, 38, 960)  0           block4h_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4h_dwconv (DepthwiseConv2D (None, 38, 38, 960)  8640        block4h_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4h_bn (BatchNormalization) (None, 38, 38, 960)  3840        block4h_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4h_activation (Activation) (None, 38, 38, 960)  0           block4h_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4h_se_squeeze (GlobalAvera (None, 960)          0           block4h_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4h_se_reshape (Reshape)    (None, 1, 1, 960)    0           block4h_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4h_se_reduce (Conv2D)      (None, 1, 1, 40)     38440       block4h_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4h_se_expand (Conv2D)      (None, 1, 1, 960)    39360       block4h_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4h_se_excite (Multiply)    (None, 38, 38, 960)  0           block4h_activation[0][0]         \n",
      "                                                                 block4h_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4h_project_conv (Conv2D)   (None, 38, 38, 160)  153600      block4h_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4h_project_bn (BatchNormal (None, 38, 38, 160)  640         block4h_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4h_drop (Dropout)          (None, 38, 38, 160)  0           block4h_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4h_add (Add)               (None, 38, 38, 160)  0           block4h_drop[0][0]               \n",
      "                                                                 block4g_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4i_expand_conv (Conv2D)    (None, 38, 38, 960)  153600      block4h_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4i_expand_bn (BatchNormali (None, 38, 38, 960)  3840        block4i_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4i_expand_activation (Acti (None, 38, 38, 960)  0           block4i_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4i_dwconv (DepthwiseConv2D (None, 38, 38, 960)  8640        block4i_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4i_bn (BatchNormalization) (None, 38, 38, 960)  3840        block4i_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4i_activation (Activation) (None, 38, 38, 960)  0           block4i_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4i_se_squeeze (GlobalAvera (None, 960)          0           block4i_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4i_se_reshape (Reshape)    (None, 1, 1, 960)    0           block4i_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4i_se_reduce (Conv2D)      (None, 1, 1, 40)     38440       block4i_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4i_se_expand (Conv2D)      (None, 1, 1, 960)    39360       block4i_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4i_se_excite (Multiply)    (None, 38, 38, 960)  0           block4i_activation[0][0]         \n",
      "                                                                 block4i_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4i_project_conv (Conv2D)   (None, 38, 38, 160)  153600      block4i_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4i_project_bn (BatchNormal (None, 38, 38, 160)  640         block4i_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4i_drop (Dropout)          (None, 38, 38, 160)  0           block4i_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4i_add (Add)               (None, 38, 38, 160)  0           block4i_drop[0][0]               \n",
      "                                                                 block4h_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4j_expand_conv (Conv2D)    (None, 38, 38, 960)  153600      block4i_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4j_expand_bn (BatchNormali (None, 38, 38, 960)  3840        block4j_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4j_expand_activation (Acti (None, 38, 38, 960)  0           block4j_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4j_dwconv (DepthwiseConv2D (None, 38, 38, 960)  8640        block4j_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4j_bn (BatchNormalization) (None, 38, 38, 960)  3840        block4j_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4j_activation (Activation) (None, 38, 38, 960)  0           block4j_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4j_se_squeeze (GlobalAvera (None, 960)          0           block4j_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4j_se_reshape (Reshape)    (None, 1, 1, 960)    0           block4j_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4j_se_reduce (Conv2D)      (None, 1, 1, 40)     38440       block4j_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4j_se_expand (Conv2D)      (None, 1, 1, 960)    39360       block4j_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4j_se_excite (Multiply)    (None, 38, 38, 960)  0           block4j_activation[0][0]         \n",
      "                                                                 block4j_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4j_project_conv (Conv2D)   (None, 38, 38, 160)  153600      block4j_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4j_project_bn (BatchNormal (None, 38, 38, 160)  640         block4j_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4j_drop (Dropout)          (None, 38, 38, 160)  0           block4j_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4j_add (Add)               (None, 38, 38, 160)  0           block4j_drop[0][0]               \n",
      "                                                                 block4i_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5a_expand_conv (Conv2D)    (None, 38, 38, 960)  153600      block4j_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5a_expand_bn (BatchNormali (None, 38, 38, 960)  3840        block5a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5a_expand_activation (Acti (None, 38, 38, 960)  0           block5a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_dwconv (DepthwiseConv2D (None, 38, 38, 960)  24000       block5a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5a_bn (BatchNormalization) (None, 38, 38, 960)  3840        block5a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5a_activation (Activation) (None, 38, 38, 960)  0           block5a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_squeeze (GlobalAvera (None, 960)          0           block5a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_reshape (Reshape)    (None, 1, 1, 960)    0           block5a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_reduce (Conv2D)      (None, 1, 1, 40)     38440       block5a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_expand (Conv2D)      (None, 1, 1, 960)    39360       block5a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_excite (Multiply)    (None, 38, 38, 960)  0           block5a_activation[0][0]         \n",
      "                                                                 block5a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_project_conv (Conv2D)   (None, 38, 38, 224)  215040      block5a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_project_bn (BatchNormal (None, 38, 38, 224)  896         block5a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5b_expand_conv (Conv2D)    (None, 38, 38, 1344) 301056      block5a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_expand_bn (BatchNormali (None, 38, 38, 1344) 5376        block5b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5b_expand_activation (Acti (None, 38, 38, 1344) 0           block5b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_dwconv (DepthwiseConv2D (None, 38, 38, 1344) 33600       block5b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5b_bn (BatchNormalization) (None, 38, 38, 1344) 5376        block5b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5b_activation (Activation) (None, 38, 38, 1344) 0           block5b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_squeeze (GlobalAvera (None, 1344)         0           block5b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_reshape (Reshape)    (None, 1, 1, 1344)   0           block5b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_reduce (Conv2D)      (None, 1, 1, 56)     75320       block5b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_expand (Conv2D)      (None, 1, 1, 1344)   76608       block5b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_excite (Multiply)    (None, 38, 38, 1344) 0           block5b_activation[0][0]         \n",
      "                                                                 block5b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_project_conv (Conv2D)   (None, 38, 38, 224)  301056      block5b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_project_bn (BatchNormal (None, 38, 38, 224)  896         block5b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5b_drop (Dropout)          (None, 38, 38, 224)  0           block5b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_add (Add)               (None, 38, 38, 224)  0           block5b_drop[0][0]               \n",
      "                                                                 block5a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_expand_conv (Conv2D)    (None, 38, 38, 1344) 301056      block5b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5c_expand_bn (BatchNormali (None, 38, 38, 1344) 5376        block5c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5c_expand_activation (Acti (None, 38, 38, 1344) 0           block5c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_dwconv (DepthwiseConv2D (None, 38, 38, 1344) 33600       block5c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5c_bn (BatchNormalization) (None, 38, 38, 1344) 5376        block5c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5c_activation (Activation) (None, 38, 38, 1344) 0           block5c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_squeeze (GlobalAvera (None, 1344)         0           block5c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_reshape (Reshape)    (None, 1, 1, 1344)   0           block5c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_reduce (Conv2D)      (None, 1, 1, 56)     75320       block5c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_expand (Conv2D)      (None, 1, 1, 1344)   76608       block5c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_excite (Multiply)    (None, 38, 38, 1344) 0           block5c_activation[0][0]         \n",
      "                                                                 block5c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_project_conv (Conv2D)   (None, 38, 38, 224)  301056      block5c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_project_bn (BatchNormal (None, 38, 38, 224)  896         block5c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5c_drop (Dropout)          (None, 38, 38, 224)  0           block5c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_add (Add)               (None, 38, 38, 224)  0           block5c_drop[0][0]               \n",
      "                                                                 block5b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5d_expand_conv (Conv2D)    (None, 38, 38, 1344) 301056      block5c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5d_expand_bn (BatchNormali (None, 38, 38, 1344) 5376        block5d_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5d_expand_activation (Acti (None, 38, 38, 1344) 0           block5d_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5d_dwconv (DepthwiseConv2D (None, 38, 38, 1344) 33600       block5d_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5d_bn (BatchNormalization) (None, 38, 38, 1344) 5376        block5d_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5d_activation (Activation) (None, 38, 38, 1344) 0           block5d_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5d_se_squeeze (GlobalAvera (None, 1344)         0           block5d_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5d_se_reshape (Reshape)    (None, 1, 1, 1344)   0           block5d_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5d_se_reduce (Conv2D)      (None, 1, 1, 56)     75320       block5d_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5d_se_expand (Conv2D)      (None, 1, 1, 1344)   76608       block5d_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5d_se_excite (Multiply)    (None, 38, 38, 1344) 0           block5d_activation[0][0]         \n",
      "                                                                 block5d_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5d_project_conv (Conv2D)   (None, 38, 38, 224)  301056      block5d_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5d_project_bn (BatchNormal (None, 38, 38, 224)  896         block5d_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5d_drop (Dropout)          (None, 38, 38, 224)  0           block5d_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5d_add (Add)               (None, 38, 38, 224)  0           block5d_drop[0][0]               \n",
      "                                                                 block5c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5e_expand_conv (Conv2D)    (None, 38, 38, 1344) 301056      block5d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5e_expand_bn (BatchNormali (None, 38, 38, 1344) 5376        block5e_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5e_expand_activation (Acti (None, 38, 38, 1344) 0           block5e_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5e_dwconv (DepthwiseConv2D (None, 38, 38, 1344) 33600       block5e_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5e_bn (BatchNormalization) (None, 38, 38, 1344) 5376        block5e_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5e_activation (Activation) (None, 38, 38, 1344) 0           block5e_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5e_se_squeeze (GlobalAvera (None, 1344)         0           block5e_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5e_se_reshape (Reshape)    (None, 1, 1, 1344)   0           block5e_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5e_se_reduce (Conv2D)      (None, 1, 1, 56)     75320       block5e_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5e_se_expand (Conv2D)      (None, 1, 1, 1344)   76608       block5e_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5e_se_excite (Multiply)    (None, 38, 38, 1344) 0           block5e_activation[0][0]         \n",
      "                                                                 block5e_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5e_project_conv (Conv2D)   (None, 38, 38, 224)  301056      block5e_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5e_project_bn (BatchNormal (None, 38, 38, 224)  896         block5e_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5e_drop (Dropout)          (None, 38, 38, 224)  0           block5e_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5e_add (Add)               (None, 38, 38, 224)  0           block5e_drop[0][0]               \n",
      "                                                                 block5d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5f_expand_conv (Conv2D)    (None, 38, 38, 1344) 301056      block5e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5f_expand_bn (BatchNormali (None, 38, 38, 1344) 5376        block5f_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5f_expand_activation (Acti (None, 38, 38, 1344) 0           block5f_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5f_dwconv (DepthwiseConv2D (None, 38, 38, 1344) 33600       block5f_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5f_bn (BatchNormalization) (None, 38, 38, 1344) 5376        block5f_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5f_activation (Activation) (None, 38, 38, 1344) 0           block5f_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5f_se_squeeze (GlobalAvera (None, 1344)         0           block5f_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5f_se_reshape (Reshape)    (None, 1, 1, 1344)   0           block5f_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5f_se_reduce (Conv2D)      (None, 1, 1, 56)     75320       block5f_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5f_se_expand (Conv2D)      (None, 1, 1, 1344)   76608       block5f_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5f_se_excite (Multiply)    (None, 38, 38, 1344) 0           block5f_activation[0][0]         \n",
      "                                                                 block5f_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5f_project_conv (Conv2D)   (None, 38, 38, 224)  301056      block5f_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5f_project_bn (BatchNormal (None, 38, 38, 224)  896         block5f_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5f_drop (Dropout)          (None, 38, 38, 224)  0           block5f_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5f_add (Add)               (None, 38, 38, 224)  0           block5f_drop[0][0]               \n",
      "                                                                 block5e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5g_expand_conv (Conv2D)    (None, 38, 38, 1344) 301056      block5f_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5g_expand_bn (BatchNormali (None, 38, 38, 1344) 5376        block5g_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5g_expand_activation (Acti (None, 38, 38, 1344) 0           block5g_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5g_dwconv (DepthwiseConv2D (None, 38, 38, 1344) 33600       block5g_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5g_bn (BatchNormalization) (None, 38, 38, 1344) 5376        block5g_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5g_activation (Activation) (None, 38, 38, 1344) 0           block5g_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5g_se_squeeze (GlobalAvera (None, 1344)         0           block5g_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5g_se_reshape (Reshape)    (None, 1, 1, 1344)   0           block5g_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5g_se_reduce (Conv2D)      (None, 1, 1, 56)     75320       block5g_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5g_se_expand (Conv2D)      (None, 1, 1, 1344)   76608       block5g_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5g_se_excite (Multiply)    (None, 38, 38, 1344) 0           block5g_activation[0][0]         \n",
      "                                                                 block5g_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5g_project_conv (Conv2D)   (None, 38, 38, 224)  301056      block5g_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5g_project_bn (BatchNormal (None, 38, 38, 224)  896         block5g_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5g_drop (Dropout)          (None, 38, 38, 224)  0           block5g_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5g_add (Add)               (None, 38, 38, 224)  0           block5g_drop[0][0]               \n",
      "                                                                 block5f_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5h_expand_conv (Conv2D)    (None, 38, 38, 1344) 301056      block5g_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5h_expand_bn (BatchNormali (None, 38, 38, 1344) 5376        block5h_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5h_expand_activation (Acti (None, 38, 38, 1344) 0           block5h_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5h_dwconv (DepthwiseConv2D (None, 38, 38, 1344) 33600       block5h_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5h_bn (BatchNormalization) (None, 38, 38, 1344) 5376        block5h_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5h_activation (Activation) (None, 38, 38, 1344) 0           block5h_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5h_se_squeeze (GlobalAvera (None, 1344)         0           block5h_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5h_se_reshape (Reshape)    (None, 1, 1, 1344)   0           block5h_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5h_se_reduce (Conv2D)      (None, 1, 1, 56)     75320       block5h_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5h_se_expand (Conv2D)      (None, 1, 1, 1344)   76608       block5h_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5h_se_excite (Multiply)    (None, 38, 38, 1344) 0           block5h_activation[0][0]         \n",
      "                                                                 block5h_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5h_project_conv (Conv2D)   (None, 38, 38, 224)  301056      block5h_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5h_project_bn (BatchNormal (None, 38, 38, 224)  896         block5h_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5h_drop (Dropout)          (None, 38, 38, 224)  0           block5h_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5h_add (Add)               (None, 38, 38, 224)  0           block5h_drop[0][0]               \n",
      "                                                                 block5g_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5i_expand_conv (Conv2D)    (None, 38, 38, 1344) 301056      block5h_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5i_expand_bn (BatchNormali (None, 38, 38, 1344) 5376        block5i_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5i_expand_activation (Acti (None, 38, 38, 1344) 0           block5i_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5i_dwconv (DepthwiseConv2D (None, 38, 38, 1344) 33600       block5i_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5i_bn (BatchNormalization) (None, 38, 38, 1344) 5376        block5i_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5i_activation (Activation) (None, 38, 38, 1344) 0           block5i_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5i_se_squeeze (GlobalAvera (None, 1344)         0           block5i_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5i_se_reshape (Reshape)    (None, 1, 1, 1344)   0           block5i_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5i_se_reduce (Conv2D)      (None, 1, 1, 56)     75320       block5i_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5i_se_expand (Conv2D)      (None, 1, 1, 1344)   76608       block5i_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5i_se_excite (Multiply)    (None, 38, 38, 1344) 0           block5i_activation[0][0]         \n",
      "                                                                 block5i_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5i_project_conv (Conv2D)   (None, 38, 38, 224)  301056      block5i_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5i_project_bn (BatchNormal (None, 38, 38, 224)  896         block5i_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5i_drop (Dropout)          (None, 38, 38, 224)  0           block5i_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5i_add (Add)               (None, 38, 38, 224)  0           block5i_drop[0][0]               \n",
      "                                                                 block5h_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5j_expand_conv (Conv2D)    (None, 38, 38, 1344) 301056      block5i_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5j_expand_bn (BatchNormali (None, 38, 38, 1344) 5376        block5j_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5j_expand_activation (Acti (None, 38, 38, 1344) 0           block5j_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5j_dwconv (DepthwiseConv2D (None, 38, 38, 1344) 33600       block5j_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5j_bn (BatchNormalization) (None, 38, 38, 1344) 5376        block5j_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5j_activation (Activation) (None, 38, 38, 1344) 0           block5j_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5j_se_squeeze (GlobalAvera (None, 1344)         0           block5j_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5j_se_reshape (Reshape)    (None, 1, 1, 1344)   0           block5j_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5j_se_reduce (Conv2D)      (None, 1, 1, 56)     75320       block5j_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5j_se_expand (Conv2D)      (None, 1, 1, 1344)   76608       block5j_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5j_se_excite (Multiply)    (None, 38, 38, 1344) 0           block5j_activation[0][0]         \n",
      "                                                                 block5j_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5j_project_conv (Conv2D)   (None, 38, 38, 224)  301056      block5j_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5j_project_bn (BatchNormal (None, 38, 38, 224)  896         block5j_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5j_drop (Dropout)          (None, 38, 38, 224)  0           block5j_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5j_add (Add)               (None, 38, 38, 224)  0           block5j_drop[0][0]               \n",
      "                                                                 block5i_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6a_expand_conv (Conv2D)    (None, 38, 38, 1344) 301056      block5j_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6a_expand_bn (BatchNormali (None, 38, 38, 1344) 5376        block6a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6a_expand_activation (Acti (None, 38, 38, 1344) 0           block6a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_dwconv_pad (ZeroPadding (None, 41, 41, 1344) 0           block6a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6a_dwconv (DepthwiseConv2D (None, 19, 19, 1344) 33600       block6a_dwconv_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_bn (BatchNormalization) (None, 19, 19, 1344) 5376        block6a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6a_activation (Activation) (None, 19, 19, 1344) 0           block6a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_squeeze (GlobalAvera (None, 1344)         0           block6a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_reshape (Reshape)    (None, 1, 1, 1344)   0           block6a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_reduce (Conv2D)      (None, 1, 1, 56)     75320       block6a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_expand (Conv2D)      (None, 1, 1, 1344)   76608       block6a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_excite (Multiply)    (None, 19, 19, 1344) 0           block6a_activation[0][0]         \n",
      "                                                                 block6a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_project_conv (Conv2D)   (None, 19, 19, 384)  516096      block6a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_project_bn (BatchNormal (None, 19, 19, 384)  1536        block6a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6b_expand_conv (Conv2D)    (None, 19, 19, 2304) 884736      block6a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_expand_bn (BatchNormali (None, 19, 19, 2304) 9216        block6b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6b_expand_activation (Acti (None, 19, 19, 2304) 0           block6b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_dwconv (DepthwiseConv2D (None, 19, 19, 2304) 57600       block6b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6b_bn (BatchNormalization) (None, 19, 19, 2304) 9216        block6b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6b_activation (Activation) (None, 19, 19, 2304) 0           block6b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_squeeze (GlobalAvera (None, 2304)         0           block6b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_reshape (Reshape)    (None, 1, 1, 2304)   0           block6b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_reduce (Conv2D)      (None, 1, 1, 96)     221280      block6b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_expand (Conv2D)      (None, 1, 1, 2304)   223488      block6b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_excite (Multiply)    (None, 19, 19, 2304) 0           block6b_activation[0][0]         \n",
      "                                                                 block6b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_project_conv (Conv2D)   (None, 19, 19, 384)  884736      block6b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_project_bn (BatchNormal (None, 19, 19, 384)  1536        block6b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6b_drop (Dropout)          (None, 19, 19, 384)  0           block6b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_add (Add)               (None, 19, 19, 384)  0           block6b_drop[0][0]               \n",
      "                                                                 block6a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_expand_conv (Conv2D)    (None, 19, 19, 2304) 884736      block6b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6c_expand_bn (BatchNormali (None, 19, 19, 2304) 9216        block6c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6c_expand_activation (Acti (None, 19, 19, 2304) 0           block6c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_dwconv (DepthwiseConv2D (None, 19, 19, 2304) 57600       block6c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6c_bn (BatchNormalization) (None, 19, 19, 2304) 9216        block6c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6c_activation (Activation) (None, 19, 19, 2304) 0           block6c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_squeeze (GlobalAvera (None, 2304)         0           block6c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_reshape (Reshape)    (None, 1, 1, 2304)   0           block6c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_reduce (Conv2D)      (None, 1, 1, 96)     221280      block6c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_expand (Conv2D)      (None, 1, 1, 2304)   223488      block6c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_excite (Multiply)    (None, 19, 19, 2304) 0           block6c_activation[0][0]         \n",
      "                                                                 block6c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_project_conv (Conv2D)   (None, 19, 19, 384)  884736      block6c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_project_bn (BatchNormal (None, 19, 19, 384)  1536        block6c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6c_drop (Dropout)          (None, 19, 19, 384)  0           block6c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_add (Add)               (None, 19, 19, 384)  0           block6c_drop[0][0]               \n",
      "                                                                 block6b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6d_expand_conv (Conv2D)    (None, 19, 19, 2304) 884736      block6c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6d_expand_bn (BatchNormali (None, 19, 19, 2304) 9216        block6d_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6d_expand_activation (Acti (None, 19, 19, 2304) 0           block6d_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_dwconv (DepthwiseConv2D (None, 19, 19, 2304) 57600       block6d_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6d_bn (BatchNormalization) (None, 19, 19, 2304) 9216        block6d_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6d_activation (Activation) (None, 19, 19, 2304) 0           block6d_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_squeeze (GlobalAvera (None, 2304)         0           block6d_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_reshape (Reshape)    (None, 1, 1, 2304)   0           block6d_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_reduce (Conv2D)      (None, 1, 1, 96)     221280      block6d_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_expand (Conv2D)      (None, 1, 1, 2304)   223488      block6d_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_excite (Multiply)    (None, 19, 19, 2304) 0           block6d_activation[0][0]         \n",
      "                                                                 block6d_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_project_conv (Conv2D)   (None, 19, 19, 384)  884736      block6d_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_project_bn (BatchNormal (None, 19, 19, 384)  1536        block6d_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6d_drop (Dropout)          (None, 19, 19, 384)  0           block6d_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_add (Add)               (None, 19, 19, 384)  0           block6d_drop[0][0]               \n",
      "                                                                 block6c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6e_expand_conv (Conv2D)    (None, 19, 19, 2304) 884736      block6d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6e_expand_bn (BatchNormali (None, 19, 19, 2304) 9216        block6e_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6e_expand_activation (Acti (None, 19, 19, 2304) 0           block6e_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6e_dwconv (DepthwiseConv2D (None, 19, 19, 2304) 57600       block6e_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6e_bn (BatchNormalization) (None, 19, 19, 2304) 9216        block6e_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6e_activation (Activation) (None, 19, 19, 2304) 0           block6e_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6e_se_squeeze (GlobalAvera (None, 2304)         0           block6e_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6e_se_reshape (Reshape)    (None, 1, 1, 2304)   0           block6e_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6e_se_reduce (Conv2D)      (None, 1, 1, 96)     221280      block6e_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6e_se_expand (Conv2D)      (None, 1, 1, 2304)   223488      block6e_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6e_se_excite (Multiply)    (None, 19, 19, 2304) 0           block6e_activation[0][0]         \n",
      "                                                                 block6e_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6e_project_conv (Conv2D)   (None, 19, 19, 384)  884736      block6e_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6e_project_bn (BatchNormal (None, 19, 19, 384)  1536        block6e_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6e_drop (Dropout)          (None, 19, 19, 384)  0           block6e_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6e_add (Add)               (None, 19, 19, 384)  0           block6e_drop[0][0]               \n",
      "                                                                 block6d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6f_expand_conv (Conv2D)    (None, 19, 19, 2304) 884736      block6e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6f_expand_bn (BatchNormali (None, 19, 19, 2304) 9216        block6f_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6f_expand_activation (Acti (None, 19, 19, 2304) 0           block6f_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6f_dwconv (DepthwiseConv2D (None, 19, 19, 2304) 57600       block6f_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6f_bn (BatchNormalization) (None, 19, 19, 2304) 9216        block6f_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6f_activation (Activation) (None, 19, 19, 2304) 0           block6f_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6f_se_squeeze (GlobalAvera (None, 2304)         0           block6f_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6f_se_reshape (Reshape)    (None, 1, 1, 2304)   0           block6f_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6f_se_reduce (Conv2D)      (None, 1, 1, 96)     221280      block6f_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6f_se_expand (Conv2D)      (None, 1, 1, 2304)   223488      block6f_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6f_se_excite (Multiply)    (None, 19, 19, 2304) 0           block6f_activation[0][0]         \n",
      "                                                                 block6f_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6f_project_conv (Conv2D)   (None, 19, 19, 384)  884736      block6f_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6f_project_bn (BatchNormal (None, 19, 19, 384)  1536        block6f_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6f_drop (Dropout)          (None, 19, 19, 384)  0           block6f_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6f_add (Add)               (None, 19, 19, 384)  0           block6f_drop[0][0]               \n",
      "                                                                 block6e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6g_expand_conv (Conv2D)    (None, 19, 19, 2304) 884736      block6f_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6g_expand_bn (BatchNormali (None, 19, 19, 2304) 9216        block6g_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6g_expand_activation (Acti (None, 19, 19, 2304) 0           block6g_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6g_dwconv (DepthwiseConv2D (None, 19, 19, 2304) 57600       block6g_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6g_bn (BatchNormalization) (None, 19, 19, 2304) 9216        block6g_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6g_activation (Activation) (None, 19, 19, 2304) 0           block6g_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6g_se_squeeze (GlobalAvera (None, 2304)         0           block6g_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6g_se_reshape (Reshape)    (None, 1, 1, 2304)   0           block6g_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6g_se_reduce (Conv2D)      (None, 1, 1, 96)     221280      block6g_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6g_se_expand (Conv2D)      (None, 1, 1, 2304)   223488      block6g_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6g_se_excite (Multiply)    (None, 19, 19, 2304) 0           block6g_activation[0][0]         \n",
      "                                                                 block6g_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6g_project_conv (Conv2D)   (None, 19, 19, 384)  884736      block6g_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6g_project_bn (BatchNormal (None, 19, 19, 384)  1536        block6g_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6g_drop (Dropout)          (None, 19, 19, 384)  0           block6g_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6g_add (Add)               (None, 19, 19, 384)  0           block6g_drop[0][0]               \n",
      "                                                                 block6f_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6h_expand_conv (Conv2D)    (None, 19, 19, 2304) 884736      block6g_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6h_expand_bn (BatchNormali (None, 19, 19, 2304) 9216        block6h_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6h_expand_activation (Acti (None, 19, 19, 2304) 0           block6h_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6h_dwconv (DepthwiseConv2D (None, 19, 19, 2304) 57600       block6h_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6h_bn (BatchNormalization) (None, 19, 19, 2304) 9216        block6h_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6h_activation (Activation) (None, 19, 19, 2304) 0           block6h_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6h_se_squeeze (GlobalAvera (None, 2304)         0           block6h_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6h_se_reshape (Reshape)    (None, 1, 1, 2304)   0           block6h_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6h_se_reduce (Conv2D)      (None, 1, 1, 96)     221280      block6h_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6h_se_expand (Conv2D)      (None, 1, 1, 2304)   223488      block6h_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6h_se_excite (Multiply)    (None, 19, 19, 2304) 0           block6h_activation[0][0]         \n",
      "                                                                 block6h_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6h_project_conv (Conv2D)   (None, 19, 19, 384)  884736      block6h_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6h_project_bn (BatchNormal (None, 19, 19, 384)  1536        block6h_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6h_drop (Dropout)          (None, 19, 19, 384)  0           block6h_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6h_add (Add)               (None, 19, 19, 384)  0           block6h_drop[0][0]               \n",
      "                                                                 block6g_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6i_expand_conv (Conv2D)    (None, 19, 19, 2304) 884736      block6h_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6i_expand_bn (BatchNormali (None, 19, 19, 2304) 9216        block6i_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6i_expand_activation (Acti (None, 19, 19, 2304) 0           block6i_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6i_dwconv (DepthwiseConv2D (None, 19, 19, 2304) 57600       block6i_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6i_bn (BatchNormalization) (None, 19, 19, 2304) 9216        block6i_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6i_activation (Activation) (None, 19, 19, 2304) 0           block6i_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6i_se_squeeze (GlobalAvera (None, 2304)         0           block6i_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6i_se_reshape (Reshape)    (None, 1, 1, 2304)   0           block6i_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6i_se_reduce (Conv2D)      (None, 1, 1, 96)     221280      block6i_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6i_se_expand (Conv2D)      (None, 1, 1, 2304)   223488      block6i_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6i_se_excite (Multiply)    (None, 19, 19, 2304) 0           block6i_activation[0][0]         \n",
      "                                                                 block6i_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6i_project_conv (Conv2D)   (None, 19, 19, 384)  884736      block6i_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6i_project_bn (BatchNormal (None, 19, 19, 384)  1536        block6i_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6i_drop (Dropout)          (None, 19, 19, 384)  0           block6i_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6i_add (Add)               (None, 19, 19, 384)  0           block6i_drop[0][0]               \n",
      "                                                                 block6h_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6j_expand_conv (Conv2D)    (None, 19, 19, 2304) 884736      block6i_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6j_expand_bn (BatchNormali (None, 19, 19, 2304) 9216        block6j_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6j_expand_activation (Acti (None, 19, 19, 2304) 0           block6j_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6j_dwconv (DepthwiseConv2D (None, 19, 19, 2304) 57600       block6j_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6j_bn (BatchNormalization) (None, 19, 19, 2304) 9216        block6j_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6j_activation (Activation) (None, 19, 19, 2304) 0           block6j_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6j_se_squeeze (GlobalAvera (None, 2304)         0           block6j_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6j_se_reshape (Reshape)    (None, 1, 1, 2304)   0           block6j_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6j_se_reduce (Conv2D)      (None, 1, 1, 96)     221280      block6j_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6j_se_expand (Conv2D)      (None, 1, 1, 2304)   223488      block6j_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6j_se_excite (Multiply)    (None, 19, 19, 2304) 0           block6j_activation[0][0]         \n",
      "                                                                 block6j_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6j_project_conv (Conv2D)   (None, 19, 19, 384)  884736      block6j_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6j_project_bn (BatchNormal (None, 19, 19, 384)  1536        block6j_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6j_drop (Dropout)          (None, 19, 19, 384)  0           block6j_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6j_add (Add)               (None, 19, 19, 384)  0           block6j_drop[0][0]               \n",
      "                                                                 block6i_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6k_expand_conv (Conv2D)    (None, 19, 19, 2304) 884736      block6j_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6k_expand_bn (BatchNormali (None, 19, 19, 2304) 9216        block6k_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6k_expand_activation (Acti (None, 19, 19, 2304) 0           block6k_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6k_dwconv (DepthwiseConv2D (None, 19, 19, 2304) 57600       block6k_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6k_bn (BatchNormalization) (None, 19, 19, 2304) 9216        block6k_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6k_activation (Activation) (None, 19, 19, 2304) 0           block6k_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6k_se_squeeze (GlobalAvera (None, 2304)         0           block6k_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6k_se_reshape (Reshape)    (None, 1, 1, 2304)   0           block6k_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6k_se_reduce (Conv2D)      (None, 1, 1, 96)     221280      block6k_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6k_se_expand (Conv2D)      (None, 1, 1, 2304)   223488      block6k_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6k_se_excite (Multiply)    (None, 19, 19, 2304) 0           block6k_activation[0][0]         \n",
      "                                                                 block6k_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6k_project_conv (Conv2D)   (None, 19, 19, 384)  884736      block6k_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6k_project_bn (BatchNormal (None, 19, 19, 384)  1536        block6k_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6k_drop (Dropout)          (None, 19, 19, 384)  0           block6k_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6k_add (Add)               (None, 19, 19, 384)  0           block6k_drop[0][0]               \n",
      "                                                                 block6j_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6l_expand_conv (Conv2D)    (None, 19, 19, 2304) 884736      block6k_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6l_expand_bn (BatchNormali (None, 19, 19, 2304) 9216        block6l_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6l_expand_activation (Acti (None, 19, 19, 2304) 0           block6l_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6l_dwconv (DepthwiseConv2D (None, 19, 19, 2304) 57600       block6l_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6l_bn (BatchNormalization) (None, 19, 19, 2304) 9216        block6l_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6l_activation (Activation) (None, 19, 19, 2304) 0           block6l_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6l_se_squeeze (GlobalAvera (None, 2304)         0           block6l_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6l_se_reshape (Reshape)    (None, 1, 1, 2304)   0           block6l_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6l_se_reduce (Conv2D)      (None, 1, 1, 96)     221280      block6l_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6l_se_expand (Conv2D)      (None, 1, 1, 2304)   223488      block6l_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6l_se_excite (Multiply)    (None, 19, 19, 2304) 0           block6l_activation[0][0]         \n",
      "                                                                 block6l_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6l_project_conv (Conv2D)   (None, 19, 19, 384)  884736      block6l_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6l_project_bn (BatchNormal (None, 19, 19, 384)  1536        block6l_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6l_drop (Dropout)          (None, 19, 19, 384)  0           block6l_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6l_add (Add)               (None, 19, 19, 384)  0           block6l_drop[0][0]               \n",
      "                                                                 block6k_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6m_expand_conv (Conv2D)    (None, 19, 19, 2304) 884736      block6l_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6m_expand_bn (BatchNormali (None, 19, 19, 2304) 9216        block6m_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6m_expand_activation (Acti (None, 19, 19, 2304) 0           block6m_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6m_dwconv (DepthwiseConv2D (None, 19, 19, 2304) 57600       block6m_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6m_bn (BatchNormalization) (None, 19, 19, 2304) 9216        block6m_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6m_activation (Activation) (None, 19, 19, 2304) 0           block6m_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6m_se_squeeze (GlobalAvera (None, 2304)         0           block6m_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6m_se_reshape (Reshape)    (None, 1, 1, 2304)   0           block6m_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6m_se_reduce (Conv2D)      (None, 1, 1, 96)     221280      block6m_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6m_se_expand (Conv2D)      (None, 1, 1, 2304)   223488      block6m_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6m_se_excite (Multiply)    (None, 19, 19, 2304) 0           block6m_activation[0][0]         \n",
      "                                                                 block6m_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6m_project_conv (Conv2D)   (None, 19, 19, 384)  884736      block6m_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6m_project_bn (BatchNormal (None, 19, 19, 384)  1536        block6m_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6m_drop (Dropout)          (None, 19, 19, 384)  0           block6m_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6m_add (Add)               (None, 19, 19, 384)  0           block6m_drop[0][0]               \n",
      "                                                                 block6l_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block7a_expand_conv (Conv2D)    (None, 19, 19, 2304) 884736      block6m_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block7a_expand_bn (BatchNormali (None, 19, 19, 2304) 9216        block7a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7a_expand_activation (Acti (None, 19, 19, 2304) 0           block7a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_dwconv (DepthwiseConv2D (None, 19, 19, 2304) 20736       block7a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block7a_bn (BatchNormalization) (None, 19, 19, 2304) 9216        block7a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block7a_activation (Activation) (None, 19, 19, 2304) 0           block7a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_squeeze (GlobalAvera (None, 2304)         0           block7a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_reshape (Reshape)    (None, 1, 1, 2304)   0           block7a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_reduce (Conv2D)      (None, 1, 1, 96)     221280      block7a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_expand (Conv2D)      (None, 1, 1, 2304)   223488      block7a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_excite (Multiply)    (None, 19, 19, 2304) 0           block7a_activation[0][0]         \n",
      "                                                                 block7a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_project_conv (Conv2D)   (None, 19, 19, 640)  1474560     block7a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_project_bn (BatchNormal (None, 19, 19, 640)  2560        block7a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block7b_expand_conv (Conv2D)    (None, 19, 19, 3840) 2457600     block7a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7b_expand_bn (BatchNormali (None, 19, 19, 3840) 15360       block7b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7b_expand_activation (Acti (None, 19, 19, 3840) 0           block7b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7b_dwconv (DepthwiseConv2D (None, 19, 19, 3840) 34560       block7b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block7b_bn (BatchNormalization) (None, 19, 19, 3840) 15360       block7b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block7b_activation (Activation) (None, 19, 19, 3840) 0           block7b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block7b_se_squeeze (GlobalAvera (None, 3840)         0           block7b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7b_se_reshape (Reshape)    (None, 1, 1, 3840)   0           block7b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7b_se_reduce (Conv2D)      (None, 1, 1, 160)    614560      block7b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7b_se_expand (Conv2D)      (None, 1, 1, 3840)   618240      block7b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7b_se_excite (Multiply)    (None, 19, 19, 3840) 0           block7b_activation[0][0]         \n",
      "                                                                 block7b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7b_project_conv (Conv2D)   (None, 19, 19, 640)  2457600     block7b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7b_project_bn (BatchNormal (None, 19, 19, 640)  2560        block7b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block7b_drop (Dropout)          (None, 19, 19, 640)  0           block7b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7b_add (Add)               (None, 19, 19, 640)  0           block7b_drop[0][0]               \n",
      "                                                                 block7a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7c_expand_conv (Conv2D)    (None, 19, 19, 3840) 2457600     block7b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block7c_expand_bn (BatchNormali (None, 19, 19, 3840) 15360       block7c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7c_expand_activation (Acti (None, 19, 19, 3840) 0           block7c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7c_dwconv (DepthwiseConv2D (None, 19, 19, 3840) 34560       block7c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block7c_bn (BatchNormalization) (None, 19, 19, 3840) 15360       block7c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block7c_activation (Activation) (None, 19, 19, 3840) 0           block7c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block7c_se_squeeze (GlobalAvera (None, 3840)         0           block7c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7c_se_reshape (Reshape)    (None, 1, 1, 3840)   0           block7c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7c_se_reduce (Conv2D)      (None, 1, 1, 160)    614560      block7c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7c_se_expand (Conv2D)      (None, 1, 1, 3840)   618240      block7c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7c_se_excite (Multiply)    (None, 19, 19, 3840) 0           block7c_activation[0][0]         \n",
      "                                                                 block7c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7c_project_conv (Conv2D)   (None, 19, 19, 640)  2457600     block7c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7c_project_bn (BatchNormal (None, 19, 19, 640)  2560        block7c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block7c_drop (Dropout)          (None, 19, 19, 640)  0           block7c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7c_add (Add)               (None, 19, 19, 640)  0           block7c_drop[0][0]               \n",
      "                                                                 block7b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block7d_expand_conv (Conv2D)    (None, 19, 19, 3840) 2457600     block7c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block7d_expand_bn (BatchNormali (None, 19, 19, 3840) 15360       block7d_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7d_expand_activation (Acti (None, 19, 19, 3840) 0           block7d_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7d_dwconv (DepthwiseConv2D (None, 19, 19, 3840) 34560       block7d_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block7d_bn (BatchNormalization) (None, 19, 19, 3840) 15360       block7d_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block7d_activation (Activation) (None, 19, 19, 3840) 0           block7d_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block7d_se_squeeze (GlobalAvera (None, 3840)         0           block7d_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7d_se_reshape (Reshape)    (None, 1, 1, 3840)   0           block7d_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7d_se_reduce (Conv2D)      (None, 1, 1, 160)    614560      block7d_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7d_se_expand (Conv2D)      (None, 1, 1, 3840)   618240      block7d_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7d_se_excite (Multiply)    (None, 19, 19, 3840) 0           block7d_activation[0][0]         \n",
      "                                                                 block7d_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7d_project_conv (Conv2D)   (None, 19, 19, 640)  2457600     block7d_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7d_project_bn (BatchNormal (None, 19, 19, 640)  2560        block7d_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block7d_drop (Dropout)          (None, 19, 19, 640)  0           block7d_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7d_add (Add)               (None, 19, 19, 640)  0           block7d_drop[0][0]               \n",
      "                                                                 block7c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "top_conv (Conv2D)               (None, 19, 19, 2560) 1638400     block7d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "top_bn (BatchNormalization)     (None, 19, 19, 2560) 10240       top_conv[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "top_activation (Activation)     (None, 19, 19, 2560) 0           top_bn[0][0]                     \n",
      "==================================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params: 64,097,680\n",
      "Trainable params: 63,786,960\n",
      "Non-trainable params: 310,720\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "with my_strategy.scope():\n",
    "    # Load pre-trained model\n",
    "    base_model = EfficientNetB7(include_top= False,\n",
    "                                input_shape = train_input_shape,\n",
    "                                weights = 'imagenet',\n",
    "                               backend =tf.keras.backend,\n",
    "                               layers = tf.keras.layers,\n",
    "                               utils = tf.keras.utils,\n",
    "                               models = tf.keras.models)\n",
    "\n",
    "    base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with my_strategy.scope():\n",
    "    avg = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
    "    output = tf.keras.layers.Dense(n_classes , activation='softmax')(avg)\n",
    "\n",
    "    model = tf.keras.Model(inputs = base_model.input, outputs = output)\n",
    "\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=tf.keras.optimizers.Nadam(learning_rate = 0.2), \n",
    "                  metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with my_strategy.scope():\n",
    "    #1.callback Tensorboard\n",
    "    try:\n",
    "        os.mkdir(\"my_logs\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    root_logdir = os.path.join(os.curdir , \"my_logs\")\n",
    "\n",
    "    def get_run_logdir():\n",
    "        import time\n",
    "        run_id = time.strftime(\"Artists_EfficientNet_%Y_%m_%d-%H_%M_%S\")\n",
    "        return os.path.join(root_logdir,run_id)\n",
    "\n",
    "    run_logdir = get_run_logdir()\n",
    "\n",
    "    tensorboard_cb = tf.keras.callbacks.TensorBoard(run_logdir)\n",
    "\n",
    "    #2.callback EarlyStopping\n",
    "    early_stopping_cb = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                         patience=13 ,\n",
    "                                                         verbose=1, \n",
    "                                                         mode='auto',\n",
    "                                                         restore_best_weights=True)\n",
    "    lr_scheduler = ReduceLROnPlateau(monitor='val_loss',\n",
    "                                  factor=0.3,\n",
    "                                  patience=3, \n",
    "                                  verbose=1,\n",
    "                                  mode='auto')\n",
    "    \n",
    "    \n",
    "    # Include the epoch in the file name (uses `str.format`)\n",
    "    try:\n",
    "        os.mkdir(\"checkpoint/\")\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    checkpoint_path = \"checkpoint/DeepArtist_Efficient_cp-{epoch:04d}.ckpt\"\n",
    "    checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "    # Create a callback that saves the model's weights every 5 epochs\n",
    "    cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path, \n",
    "                                                     verbose=1, \n",
    "                                                     save_weights_only=True,\n",
    "                                                     save_freq = 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 53 steps, validate for 9 steps\n",
      "Epoch 1/10\n",
      "INFO:tensorflow:batch_all_reduce: 2 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "INFO:tensorflow:batch_all_reduce: 2 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "53/53 [==============================] - 871s 16s/step - loss: 719.2691 - accuracy: 0.0944 - val_loss: 121.7538 - val_accuracy: 0.2144\n",
      "Epoch 2/10\n",
      "53/53 [==============================] - 757s 14s/step - loss: 318.6192 - accuracy: 0.1913 - val_loss: 162.0526 - val_accuracy: 0.2526\n",
      "Epoch 3/10\n",
      "53/53 [==============================] - 758s 14s/step - loss: 267.8905 - accuracy: 0.2242 - val_loss: 131.1874 - val_accuracy: 0.2726\n",
      "Epoch 4/10\n",
      "53/53 [==============================] - 757s 14s/step - loss: 276.4034 - accuracy: 0.2333 - val_loss: 120.6249 - val_accuracy: 0.3307\n",
      "Epoch 5/10\n",
      "53/53 [==============================] - 760s 14s/step - loss: 244.2335 - accuracy: 0.2703 - val_loss: 115.0508 - val_accuracy: 0.3542\n",
      "Epoch 6/10\n",
      "53/53 [==============================] - 756s 14s/step - loss: 262.9851 - accuracy: 0.2728 - val_loss: 126.6308 - val_accuracy: 0.3967\n",
      "Epoch 7/10\n",
      "53/53 [==============================] - 759s 14s/step - loss: 236.3870 - accuracy: 0.2930 - val_loss: 105.5295 - val_accuracy: 0.3828\n",
      "Epoch 8/10\n",
      "53/53 [==============================] - 758s 14s/step - loss: 202.5521 - accuracy: 0.3187 - val_loss: 106.4175 - val_accuracy: 0.4028\n",
      "Epoch 9/10\n",
      "53/53 [==============================] - 761s 14s/step - loss: 226.6066 - accuracy: 0.3116 - val_loss: 126.0195 - val_accuracy: 0.4384\n",
      "Epoch 10/10\n",
      "53/53 [==============================] - 759s 14s/step - loss: 201.5096 - accuracy: 0.3268 - val_loss: 105.4382 - val_accuracy: 0.4262\n"
     ]
    }
   ],
   "source": [
    "n_epoch = 10\n",
    "with my_strategy.scope():\n",
    "\n",
    "    history_1 = model.fit_generator(generator=train_generator, steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                          validation_data=valid_generator, validation_steps=STEP_SIZE_VALID,\n",
    "                          epochs=n_epoch,\n",
    "                          shuffle=True,\n",
    "                          verbose=1,\n",
    "                          callbacks=[lr_scheduler,early_stopping_cb,tensorboard_cb, cp_callback],\n",
    "                          class_weight=CLASS_WEIGHT\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with my_strategy.scope():\n",
    "    # Save or load the weights using the `checkpoint_path` format\n",
    "    #model.save_weights(checkpoint_path.format(epoch=10))\n",
    "    model.load_weights(checkpoint_path.format(epoch=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    if 'top' in layer.name:\n",
    "        layer.trainable = True\n",
    "    #if layer.trainable:\n",
    "    #    print(layer.name , \"is trainable!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 53 steps, validate for 9 steps\n",
      "Epoch 1/10\n",
      "INFO:tensorflow:batch_all_reduce: 5 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "53/53 [==============================] - 870s 16s/step - loss: 102.9106 - accuracy: 0.3439 - val_loss: 91.4463 - val_accuracy: 0.4392\n",
      "Epoch 2/10\n",
      "53/53 [==============================] - 759s 14s/step - loss: 74.2895 - accuracy: 0.3987 - val_loss: 69.9300 - val_accuracy: 0.4740\n",
      "Epoch 3/10\n",
      "53/53 [==============================] - 761s 14s/step - loss: 62.8792 - accuracy: 0.4076 - val_loss: 63.2924 - val_accuracy: 0.4540\n",
      "Epoch 4/10\n",
      "53/53 [==============================] - 758s 14s/step - loss: 58.1827 - accuracy: 0.4246 - val_loss: 62.0097 - val_accuracy: 0.4071\n",
      "Epoch 5/10\n",
      "53/53 [==============================] - 760s 14s/step - loss: 54.3062 - accuracy: 0.4302 - val_loss: 57.2689 - val_accuracy: 0.4453\n",
      "Epoch 6/10\n",
      "53/53 [==============================] - 761s 14s/step - loss: 49.0394 - accuracy: 0.4500 - val_loss: 49.0664 - val_accuracy: 0.4722\n",
      "Epoch 7/10\n",
      "53/53 [==============================] - 758s 14s/step - loss: 46.3763 - accuracy: 0.4550 - val_loss: 45.5733 - val_accuracy: 0.4757\n",
      "Epoch 8/10\n",
      "53/53 [==============================] - 757s 14s/step - loss: 42.5577 - accuracy: 0.4523 - val_loss: 42.6190 - val_accuracy: 0.5026\n",
      "Epoch 9/10\n",
      "53/53 [==============================] - 759s 14s/step - loss: 42.1847 - accuracy: 0.4636 - val_loss: 45.1470 - val_accuracy: 0.4661\n",
      "Epoch 10/10\n",
      "53/53 [==============================] - 759s 14s/step - loss: 39.1009 - accuracy: 0.4650 - val_loss: 38.2652 - val_accuracy: 0.4991\n"
     ]
    }
   ],
   "source": [
    "n_epoch = 10\n",
    "with my_strategy.scope():\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=tf.keras.optimizers.Nadam(learning_rate = 0.001), # reduce the lr from 0.1 to 0.001\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    history_2 = model.fit_generator(generator=train_generator, steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                          validation_data=valid_generator, validation_steps=STEP_SIZE_VALID,\n",
    "                          epochs=n_epoch,\n",
    "                          shuffle=True,\n",
    "                          verbose=1,\n",
    "                          callbacks=[lr_scheduler,early_stopping_cb,tensorboard_cb],\n",
    "                          class_weight=CLASS_WEIGHT\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with my_strategy.scope():\n",
    "    # Save or load the weights using the `checkpoint_path` format\n",
    "    #model.save_weights(checkpoint_path.format(epoch=20))\n",
    "    model.load_weights(checkpoint_path.format(epoch=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    if 'block7' in layer.name:\n",
    "        layer.trainable = True\n",
    "    \n",
    "    #if layer.trainable:\n",
    "    #    print(layer.name , \"is trainable!\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 53 steps, validate for 9 steps\n",
      "Epoch 1/30\n",
      "53/53 [==============================] - 909s 17s/step - loss: 38.2921 - accuracy: 0.4073 - val_loss: 35.3211 - val_accuracy: 0.5017\n",
      "Epoch 2/30\n",
      "53/53 [==============================] - 761s 14s/step - loss: 25.5615 - accuracy: 0.4301 - val_loss: 29.6558 - val_accuracy: 0.4991\n",
      "Epoch 3/30\n",
      "53/53 [==============================] - 767s 14s/step - loss: 20.7765 - accuracy: 0.4609 - val_loss: 23.7631 - val_accuracy: 0.5208\n",
      "Epoch 4/30\n",
      "53/53 [==============================] - 763s 14s/step - loss: 17.2977 - accuracy: 0.4846 - val_loss: 20.3083 - val_accuracy: 0.4653\n",
      "Epoch 5/30\n",
      "53/53 [==============================] - 763s 14s/step - loss: 15.5372 - accuracy: 0.4927 - val_loss: 18.7141 - val_accuracy: 0.5304\n",
      "Epoch 6/30\n",
      "53/53 [==============================] - 761s 14s/step - loss: 13.7063 - accuracy: 0.5046 - val_loss: 17.9782 - val_accuracy: 0.5269\n",
      "Epoch 7/30\n",
      "53/53 [==============================] - 764s 14s/step - loss: 12.8770 - accuracy: 0.5232 - val_loss: 16.5444 - val_accuracy: 0.4974\n",
      "Epoch 8/30\n",
      "53/53 [==============================] - 761s 14s/step - loss: 11.0724 - accuracy: 0.5460 - val_loss: 15.2088 - val_accuracy: 0.5095\n",
      "Epoch 9/30\n",
      "53/53 [==============================] - 759s 14s/step - loss: 10.3133 - accuracy: 0.5373 - val_loss: 13.7327 - val_accuracy: 0.5052\n",
      "Epoch 10/30\n",
      "53/53 [==============================] - 760s 14s/step - loss: 10.1658 - accuracy: 0.5362 - val_loss: 15.2580 - val_accuracy: 0.4757\n",
      "Epoch 11/30\n",
      "53/53 [==============================] - 763s 14s/step - loss: 9.3570 - accuracy: 0.5514 - val_loss: 13.4466 - val_accuracy: 0.5339\n",
      "Epoch 12/30\n",
      "53/53 [==============================] - 760s 14s/step - loss: 8.8892 - accuracy: 0.5613 - val_loss: 13.5165 - val_accuracy: 0.4931\n",
      "Epoch 13/30\n",
      "53/53 [==============================] - 761s 14s/step - loss: 8.2774 - accuracy: 0.5775 - val_loss: 12.8906 - val_accuracy: 0.5304\n",
      "Epoch 14/30\n",
      "53/53 [==============================] - 762s 14s/step - loss: 8.0881 - accuracy: 0.5673 - val_loss: 12.9719 - val_accuracy: 0.5078\n",
      "Epoch 15/30\n",
      "53/53 [==============================] - 761s 14s/step - loss: 7.8508 - accuracy: 0.5820 - val_loss: 11.5825 - val_accuracy: 0.5451\n",
      "Epoch 16/30\n",
      "53/53 [==============================] - 762s 14s/step - loss: 7.6901 - accuracy: 0.5743 - val_loss: 12.2404 - val_accuracy: 0.5078\n",
      "Epoch 17/30\n",
      "53/53 [==============================] - 762s 14s/step - loss: 7.0210 - accuracy: 0.6093 - val_loss: 11.4552 - val_accuracy: 0.5191\n",
      "Epoch 18/30\n",
      "53/53 [==============================] - 759s 14s/step - loss: 6.9272 - accuracy: 0.6126 - val_loss: 11.8009 - val_accuracy: 0.5148\n",
      "Epoch 19/30\n",
      "53/53 [==============================] - 761s 14s/step - loss: 6.6859 - accuracy: 0.6194 - val_loss: 14.3205 - val_accuracy: 0.4679\n",
      "Epoch 20/30\n",
      "52/53 [============================>.] - ETA: 12s - loss: 6.8126 - accuracy: 0.6137\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "Restoring model weights from the end of the best epoch.\n",
      "53/53 [==============================] - 765s 14s/step - loss: 6.8127 - accuracy: 0.6126 - val_loss: 11.7270 - val_accuracy: 0.5148\n",
      "Epoch 00020: early stopping\n"
     ]
    }
   ],
   "source": [
    "n_epoch = 30\n",
    "with my_strategy.scope():\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=tf.keras.optimizers.Nadam(learning_rate = 0.0001), # reduce the lr from 0.1 to 0.001\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    history_3 = model.fit_generator(generator=train_generator, steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                          validation_data=valid_generator, validation_steps=STEP_SIZE_VALID,\n",
    "                          epochs=n_epoch,\n",
    "                          shuffle=True,\n",
    "                          verbose=1,\n",
    "                          callbacks=[lr_scheduler,early_stopping_cb,tensorboard_cb],\n",
    "                          class_weight=CLASS_WEIGHT\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-436.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.momentum_cache\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-436.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-436.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-436.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-436.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    }
   ],
   "source": [
    "with my_strategy.scope():\n",
    "\n",
    "    # Save or load the weights using the `checkpoint_path` format\n",
    "    #model.save_weights(checkpoint_path.format(epoch=40))\n",
    "    model.load_weights(checkpoint_path.format(epoch=40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-14-37777441f82f>:13: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 53 steps, validate for 9 steps\n",
      "Epoch 1/30\n",
      "INFO:tensorflow:batch_all_reduce: 57 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "INFO:tensorflow:batch_all_reduce: 57 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "53/53 [==============================] - 895s 17s/step - loss: 7.1957 - accuracy: 0.5974 - val_loss: 11.5873 - val_accuracy: 0.5304\n",
      "Epoch 2/30\n",
      "53/53 [==============================] - 763s 14s/step - loss: 7.2712 - accuracy: 0.6031 - val_loss: 11.1546 - val_accuracy: 0.5373\n",
      "Epoch 3/30\n",
      "53/53 [==============================] - 763s 14s/step - loss: 7.0947 - accuracy: 0.6087 - val_loss: 10.8908 - val_accuracy: 0.5130\n",
      "Epoch 4/30\n",
      "53/53 [==============================] - 762s 14s/step - loss: 6.5908 - accuracy: 0.6093 - val_loss: 10.6889 - val_accuracy: 0.5260\n",
      "Epoch 5/30\n",
      "53/53 [==============================] - 762s 14s/step - loss: 6.4424 - accuracy: 0.6149 - val_loss: 10.4908 - val_accuracy: 0.5269\n",
      "Epoch 6/30\n",
      "52/53 [============================>.] - ETA: 12s - loss: 6.2663 - accuracy: 0.6238\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "53/53 [==============================] - 760s 14s/step - loss: 6.2422 - accuracy: 0.6243 - val_loss: 11.9952 - val_accuracy: 0.5026\n",
      "Epoch 7/30\n",
      "52/53 [============================>.] - ETA: 12s - loss: 6.0046 - accuracy: 0.6323\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "53/53 [==============================] - 763s 14s/step - loss: 5.9980 - accuracy: 0.6331 - val_loss: 10.7870 - val_accuracy: 0.5304\n",
      "Epoch 8/30\n",
      "52/53 [============================>.] - ETA: 12s - loss: 5.9392 - accuracy: 0.6353\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "Restoring model weights from the end of the best epoch.\n",
      "53/53 [==============================] - 765s 14s/step - loss: 5.9294 - accuracy: 0.6357 - val_loss: 10.8532 - val_accuracy: 0.5469\n",
      "Epoch 00008: early stopping\n"
     ]
    }
   ],
   "source": [
    "n_epoch = 30\n",
    "with my_strategy.scope():\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=tf.keras.optimizers.Nadam(learning_rate = 0.00005), # reduce the lr from 0.1 to 0.0005\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    history_4 = model.fit_generator(generator=train_generator, steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                          validation_data=valid_generator, validation_steps=STEP_SIZE_VALID,\n",
    "                          epochs=n_epoch,\n",
    "                          shuffle=True,\n",
    "                          verbose=1,\n",
    "                          callbacks=[lr_scheduler,early_stopping_cb,tensorboard_cb],\n",
    "                          class_weight=CLASS_WEIGHT\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with my_strategy.scope():\n",
    "\n",
    "    # Save or load the weights using the `checkpoint_path` format\n",
    "    #model.save_weights(checkpoint_path.format(epoch=47))\n",
    "    model.load_weights(checkpoint_path.format(epoch=47))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    if 'block6' in layer.name:\n",
    "        layer.trainable = True\n",
    "    \n",
    "    #if layer.trainable:\n",
    "    #    print(layer.name , \"is trainable!\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 214 steps, validate for 37 steps\n",
      "Epoch 1/30\n",
      "INFO:tensorflow:batch_all_reduce: 226 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "INFO:tensorflow:batch_all_reduce: 226 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "214/214 [==============================] - 1206s 6s/step - loss: 11.5400 - accuracy: 0.4982 - val_loss: 11.5402 - val_accuracy: 0.5177\n",
      "Epoch 2/30\n",
      "214/214 [==============================] - 884s 4s/step - loss: 10.3421 - accuracy: 0.4999 - val_loss: 11.0236 - val_accuracy: 0.5144\n",
      "Epoch 3/30\n",
      "214/214 [==============================] - 891s 4s/step - loss: 9.4719 - accuracy: 0.5193 - val_loss: 10.7728 - val_accuracy: 0.5135\n",
      "Epoch 4/30\n",
      "214/214 [==============================] - 891s 4s/step - loss: 9.2350 - accuracy: 0.5277 - val_loss: 10.6949 - val_accuracy: 0.5186\n",
      "Epoch 5/30\n",
      "214/214 [==============================] - 882s 4s/step - loss: 8.6102 - accuracy: 0.5369 - val_loss: 10.2603 - val_accuracy: 0.5296\n",
      "Epoch 6/30\n",
      "213/214 [============================>.] - ETA: 3s - loss: 8.4581 - accuracy: 0.5375\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "214/214 [==============================] - 884s 4s/step - loss: 8.4472 - accuracy: 0.5378 - val_loss: 10.3844 - val_accuracy: 0.5321\n",
      "Epoch 7/30\n",
      "213/214 [============================>.] - ETA: 3s - loss: 8.2236 - accuracy: 0.5600\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "214/214 [==============================] - 893s 4s/step - loss: 8.2174 - accuracy: 0.5597 - val_loss: 10.5977 - val_accuracy: 0.5372\n",
      "Epoch 8/30\n",
      "213/214 [============================>.] - ETA: 3s - loss: 7.9448 - accuracy: 0.5597\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "Restoring model weights from the end of the best epoch.\n",
      "214/214 [==============================] - 890s 4s/step - loss: 7.9423 - accuracy: 0.5593 - val_loss: 10.3695 - val_accuracy: 0.5363\n",
      "Epoch 00008: early stopping\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n_epoch = 30\n",
    "with my_strategy.scope():\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=tf.keras.optimizers.Nadam(learning_rate = 0.00001), # reduce the lr from 0.1 to 0.0005\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    history_5 = model.fit_generator(generator=train_generator, steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                          validation_data=valid_generator, validation_steps=STEP_SIZE_VALID,\n",
    "                          epochs=n_epoch,\n",
    "                          shuffle=True,\n",
    "                          verbose=1,\n",
    "                          callbacks=[lr_scheduler,early_stopping_cb,tensorboard_cb],\n",
    "                          class_weight=CLASS_WEIGHT\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 214 steps, validate for 37 steps\n",
      "Epoch 1/50\n",
      "INFO:tensorflow:batch_all_reduce: 226 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "INFO:tensorflow:batch_all_reduce: 226 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "214/214 [==============================] - 1091s 5s/step - loss: 8.6219 - accuracy: 0.5451 - val_loss: 11.1337 - val_accuracy: 0.5245\n",
      "Epoch 2/50\n",
      "214/214 [==============================] - 888s 4s/step - loss: 8.0030 - accuracy: 0.5501 - val_loss: 10.2519 - val_accuracy: 0.5405\n",
      "Epoch 3/50\n",
      "214/214 [==============================] - 882s 4s/step - loss: 7.9934 - accuracy: 0.5600 - val_loss: 10.5764 - val_accuracy: 0.5160\n",
      "Epoch 4/50\n",
      "214/214 [==============================] - 883s 4s/step - loss: 7.7308 - accuracy: 0.5622 - val_loss: 10.3852 - val_accuracy: 0.5262\n",
      "Epoch 5/50\n",
      "214/214 [==============================] - 885s 4s/step - loss: 7.3213 - accuracy: 0.5754 - val_loss: 10.1693 - val_accuracy: 0.5152\n",
      "Epoch 6/50\n",
      "214/214 [==============================] - 886s 4s/step - loss: 7.2669 - accuracy: 0.5829 - val_loss: 9.9111 - val_accuracy: 0.5481\n",
      "Epoch 7/50\n",
      "214/214 [==============================] - 889s 4s/step - loss: 7.1398 - accuracy: 0.5826 - val_loss: 9.3355 - val_accuracy: 0.5549\n",
      "Epoch 8/50\n",
      "214/214 [==============================] - 893s 4s/step - loss: 7.1471 - accuracy: 0.5851 - val_loss: 9.7774 - val_accuracy: 0.5363\n",
      "Epoch 9/50\n",
      "214/214 [==============================] - 887s 4s/step - loss: 6.8627 - accuracy: 0.5805 - val_loss: 10.0128 - val_accuracy: 0.5659\n",
      "Epoch 10/50\n",
      "213/214 [============================>.] - ETA: 3s - loss: 6.7906 - accuracy: 0.5984\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "214/214 [==============================] - 889s 4s/step - loss: 6.7859 - accuracy: 0.5980 - val_loss: 10.2627 - val_accuracy: 0.5608\n",
      "Epoch 11/50\n",
      "214/214 [==============================] - 883s 4s/step - loss: 6.3615 - accuracy: 0.6035 - val_loss: 10.5414 - val_accuracy: 0.5481\n",
      "Epoch 12/50\n",
      "214/214 [==============================] - 882s 4s/step - loss: 6.4602 - accuracy: 0.6042 - val_loss: 9.7705 - val_accuracy: 0.5600\n",
      "Epoch 13/50\n",
      "213/214 [============================>.] - ETA: 3s - loss: 6.3003 - accuracy: 0.6096\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "214/214 [==============================] - 886s 4s/step - loss: 6.2916 - accuracy: 0.6095 - val_loss: 9.9461 - val_accuracy: 0.5481\n",
      "Epoch 14/50\n",
      "213/214 [============================>.] - ETA: 3s - loss: 6.2833 - accuracy: 0.6150Restoring model weights from the end of the best epoch.\n",
      "214/214 [==============================] - 888s 4s/step - loss: 6.2715 - accuracy: 0.6154 - val_loss: 9.7301 - val_accuracy: 0.5633\n",
      "Epoch 00014: early stopping\n"
     ]
    }
   ],
   "source": [
    "n_epoch = 50\n",
    "with my_strategy.scope():\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=tf.keras.optimizers.Nadam(learning_rate = 0.00001), # reduce the lr from 0.1 to 0.000001\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    history_6 = model.fit_generator(generator=train_generator, steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                          validation_data=valid_generator, validation_steps=STEP_SIZE_VALID,\n",
    "                          epochs=n_epoch,\n",
    "                          shuffle=True,\n",
    "                          verbose=1,\n",
    "                          callbacks=[lr_scheduler,early_stopping_cb,tensorboard_cb],\n",
    "                          class_weight=CLASS_WEIGHT\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with my_strategy.scope():\n",
    "\n",
    "    # Save or load the weights using the `checkpoint_path` format\n",
    "    #model.save_weights(checkpoint_path.format(epoch=61))\n",
    "    model.load_weights(checkpoint_path.format(epoch=61))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 214 steps, validate for 37 steps\n",
      "Epoch 1/10\n",
      "INFO:tensorflow:batch_all_reduce: 226 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "INFO:tensorflow:batch_all_reduce: 226 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "214/214 [==============================] - 1100s 5s/step - loss: 9.4659 - accuracy: 0.5337 - val_loss: 9.5219 - val_accuracy: 0.5752\n",
      "Epoch 2/10\n",
      "214/214 [==============================] - 886s 4s/step - loss: 8.1164 - accuracy: 0.5640 - val_loss: 9.4918 - val_accuracy: 0.6039\n",
      "Epoch 3/10\n",
      "214/214 [==============================] - 892s 4s/step - loss: 7.9197 - accuracy: 0.5827 - val_loss: 10.1296 - val_accuracy: 0.5718\n",
      "Epoch 4/10\n",
      "214/214 [==============================] - 891s 4s/step - loss: 6.7602 - accuracy: 0.6165 - val_loss: 8.7930 - val_accuracy: 0.6073\n",
      "Epoch 5/10\n",
      "214/214 [==============================] - 892s 4s/step - loss: 6.1228 - accuracy: 0.6357 - val_loss: 8.3460 - val_accuracy: 0.6546\n",
      "Epoch 6/10\n",
      "214/214 [==============================] - 897s 4s/step - loss: 5.5418 - accuracy: 0.6549 - val_loss: 7.8811 - val_accuracy: 0.6394\n",
      "Epoch 7/10\n",
      "214/214 [==============================] - 889s 4s/step - loss: 5.3948 - accuracy: 0.6726 - val_loss: 7.5775 - val_accuracy: 0.6461\n",
      "Epoch 8/10\n",
      "214/214 [==============================] - 890s 4s/step - loss: 4.8874 - accuracy: 0.6789 - val_loss: 8.0618 - val_accuracy: 0.6748\n",
      "Epoch 9/10\n",
      "214/214 [==============================] - 896s 4s/step - loss: 4.4490 - accuracy: 0.7007 - val_loss: 7.8470 - val_accuracy: 0.6630\n",
      "Epoch 10/10\n",
      "213/214 [============================>.] - ETA: 3s - loss: 4.2023 - accuracy: 0.7143\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 2.9999999242136255e-05.\n",
      "214/214 [==============================] - 889s 4s/step - loss: 4.1948 - accuracy: 0.7143 - val_loss: 7.9385 - val_accuracy: 0.6689\n"
     ]
    }
   ],
   "source": [
    "n_epoch = 10\n",
    "with my_strategy.scope():\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=tf.keras.optimizers.Nadam(learning_rate = 0.0001), # raise lr a bit\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    history_7 = model.fit_generator(generator=train_generator, steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                          validation_data=valid_generator, validation_steps=STEP_SIZE_VALID,\n",
    "                          epochs=n_epoch,\n",
    "                          shuffle=True,\n",
    "                          verbose=1,\n",
    "                          callbacks=[lr_scheduler,early_stopping_cb,tensorboard_cb],\n",
    "                          class_weight=CLASS_WEIGHT\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with my_strategy.scope():\n",
    "\n",
    "    # Save or load the weights using the `checkpoint_path` format\n",
    "    #model.save_weights(checkpoint_path.format(epoch=71))\n",
    "    model.load_weights(checkpoint_path.format(epoch=71))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block5a_expand_conv is trainable!\n",
      "block5a_expand_bn is trainable!\n",
      "block5a_expand_activation is trainable!\n",
      "block5a_dwconv is trainable!\n",
      "block5a_bn is trainable!\n",
      "block5a_activation is trainable!\n",
      "block5a_se_squeeze is trainable!\n",
      "block5a_se_reshape is trainable!\n",
      "block5a_se_reduce is trainable!\n",
      "block5a_se_expand is trainable!\n",
      "block5a_se_excite is trainable!\n",
      "block5a_project_conv is trainable!\n",
      "block5a_project_bn is trainable!\n",
      "block5b_expand_conv is trainable!\n",
      "block5b_expand_bn is trainable!\n",
      "block5b_expand_activation is trainable!\n",
      "block5b_dwconv is trainable!\n",
      "block5b_bn is trainable!\n",
      "block5b_activation is trainable!\n",
      "block5b_se_squeeze is trainable!\n",
      "block5b_se_reshape is trainable!\n",
      "block5b_se_reduce is trainable!\n",
      "block5b_se_expand is trainable!\n",
      "block5b_se_excite is trainable!\n",
      "block5b_project_conv is trainable!\n",
      "block5b_project_bn is trainable!\n",
      "block5b_drop is trainable!\n",
      "block5b_add is trainable!\n",
      "block5c_expand_conv is trainable!\n",
      "block5c_expand_bn is trainable!\n",
      "block5c_expand_activation is trainable!\n",
      "block5c_dwconv is trainable!\n",
      "block5c_bn is trainable!\n",
      "block5c_activation is trainable!\n",
      "block5c_se_squeeze is trainable!\n",
      "block5c_se_reshape is trainable!\n",
      "block5c_se_reduce is trainable!\n",
      "block5c_se_expand is trainable!\n",
      "block5c_se_excite is trainable!\n",
      "block5c_project_conv is trainable!\n",
      "block5c_project_bn is trainable!\n",
      "block5c_drop is trainable!\n",
      "block5c_add is trainable!\n",
      "block5d_expand_conv is trainable!\n",
      "block5d_expand_bn is trainable!\n",
      "block5d_expand_activation is trainable!\n",
      "block5d_dwconv is trainable!\n",
      "block5d_bn is trainable!\n",
      "block5d_activation is trainable!\n",
      "block5d_se_squeeze is trainable!\n",
      "block5d_se_reshape is trainable!\n",
      "block5d_se_reduce is trainable!\n",
      "block5d_se_expand is trainable!\n",
      "block5d_se_excite is trainable!\n",
      "block5d_project_conv is trainable!\n",
      "block5d_project_bn is trainable!\n",
      "block5d_drop is trainable!\n",
      "block5d_add is trainable!\n",
      "block5e_expand_conv is trainable!\n",
      "block5e_expand_bn is trainable!\n",
      "block5e_expand_activation is trainable!\n",
      "block5e_dwconv is trainable!\n",
      "block5e_bn is trainable!\n",
      "block5e_activation is trainable!\n",
      "block5e_se_squeeze is trainable!\n",
      "block5e_se_reshape is trainable!\n",
      "block5e_se_reduce is trainable!\n",
      "block5e_se_expand is trainable!\n",
      "block5e_se_excite is trainable!\n",
      "block5e_project_conv is trainable!\n",
      "block5e_project_bn is trainable!\n",
      "block5e_drop is trainable!\n",
      "block5e_add is trainable!\n",
      "block5f_expand_conv is trainable!\n",
      "block5f_expand_bn is trainable!\n",
      "block5f_expand_activation is trainable!\n",
      "block5f_dwconv is trainable!\n",
      "block5f_bn is trainable!\n",
      "block5f_activation is trainable!\n",
      "block5f_se_squeeze is trainable!\n",
      "block5f_se_reshape is trainable!\n",
      "block5f_se_reduce is trainable!\n",
      "block5f_se_expand is trainable!\n",
      "block5f_se_excite is trainable!\n",
      "block5f_project_conv is trainable!\n",
      "block5f_project_bn is trainable!\n",
      "block5f_drop is trainable!\n",
      "block5f_add is trainable!\n",
      "block5g_expand_conv is trainable!\n",
      "block5g_expand_bn is trainable!\n",
      "block5g_expand_activation is trainable!\n",
      "block5g_dwconv is trainable!\n",
      "block5g_bn is trainable!\n",
      "block5g_activation is trainable!\n",
      "block5g_se_squeeze is trainable!\n",
      "block5g_se_reshape is trainable!\n",
      "block5g_se_reduce is trainable!\n",
      "block5g_se_expand is trainable!\n",
      "block5g_se_excite is trainable!\n",
      "block5g_project_conv is trainable!\n",
      "block5g_project_bn is trainable!\n",
      "block5g_drop is trainable!\n",
      "block5g_add is trainable!\n",
      "block5h_expand_conv is trainable!\n",
      "block5h_expand_bn is trainable!\n",
      "block5h_expand_activation is trainable!\n",
      "block5h_dwconv is trainable!\n",
      "block5h_bn is trainable!\n",
      "block5h_activation is trainable!\n",
      "block5h_se_squeeze is trainable!\n",
      "block5h_se_reshape is trainable!\n",
      "block5h_se_reduce is trainable!\n",
      "block5h_se_expand is trainable!\n",
      "block5h_se_excite is trainable!\n",
      "block5h_project_conv is trainable!\n",
      "block5h_project_bn is trainable!\n",
      "block5h_drop is trainable!\n",
      "block5h_add is trainable!\n",
      "block5i_expand_conv is trainable!\n",
      "block5i_expand_bn is trainable!\n",
      "block5i_expand_activation is trainable!\n",
      "block5i_dwconv is trainable!\n",
      "block5i_bn is trainable!\n",
      "block5i_activation is trainable!\n",
      "block5i_se_squeeze is trainable!\n",
      "block5i_se_reshape is trainable!\n",
      "block5i_se_reduce is trainable!\n",
      "block5i_se_expand is trainable!\n",
      "block5i_se_excite is trainable!\n",
      "block5i_project_conv is trainable!\n",
      "block5i_project_bn is trainable!\n",
      "block5i_drop is trainable!\n",
      "block5i_add is trainable!\n",
      "block5j_expand_conv is trainable!\n",
      "block5j_expand_bn is trainable!\n",
      "block5j_expand_activation is trainable!\n",
      "block5j_dwconv is trainable!\n",
      "block5j_bn is trainable!\n",
      "block5j_activation is trainable!\n",
      "block5j_se_squeeze is trainable!\n",
      "block5j_se_reshape is trainable!\n",
      "block5j_se_reduce is trainable!\n",
      "block5j_se_expand is trainable!\n",
      "block5j_se_excite is trainable!\n",
      "block5j_project_conv is trainable!\n",
      "block5j_project_bn is trainable!\n",
      "block5j_drop is trainable!\n",
      "block5j_add is trainable!\n",
      "block6a_expand_conv is trainable!\n",
      "block6a_expand_bn is trainable!\n",
      "block6a_expand_activation is trainable!\n",
      "block6a_dwconv_pad is trainable!\n",
      "block6a_dwconv is trainable!\n",
      "block6a_bn is trainable!\n",
      "block6a_activation is trainable!\n",
      "block6a_se_squeeze is trainable!\n",
      "block6a_se_reshape is trainable!\n",
      "block6a_se_reduce is trainable!\n",
      "block6a_se_expand is trainable!\n",
      "block6a_se_excite is trainable!\n",
      "block6a_project_conv is trainable!\n",
      "block6a_project_bn is trainable!\n",
      "block6b_expand_conv is trainable!\n",
      "block6b_expand_bn is trainable!\n",
      "block6b_expand_activation is trainable!\n",
      "block6b_dwconv is trainable!\n",
      "block6b_bn is trainable!\n",
      "block6b_activation is trainable!\n",
      "block6b_se_squeeze is trainable!\n",
      "block6b_se_reshape is trainable!\n",
      "block6b_se_reduce is trainable!\n",
      "block6b_se_expand is trainable!\n",
      "block6b_se_excite is trainable!\n",
      "block6b_project_conv is trainable!\n",
      "block6b_project_bn is trainable!\n",
      "block6b_drop is trainable!\n",
      "block6b_add is trainable!\n",
      "block6c_expand_conv is trainable!\n",
      "block6c_expand_bn is trainable!\n",
      "block6c_expand_activation is trainable!\n",
      "block6c_dwconv is trainable!\n",
      "block6c_bn is trainable!\n",
      "block6c_activation is trainable!\n",
      "block6c_se_squeeze is trainable!\n",
      "block6c_se_reshape is trainable!\n",
      "block6c_se_reduce is trainable!\n",
      "block6c_se_expand is trainable!\n",
      "block6c_se_excite is trainable!\n",
      "block6c_project_conv is trainable!\n",
      "block6c_project_bn is trainable!\n",
      "block6c_drop is trainable!\n",
      "block6c_add is trainable!\n",
      "block6d_expand_conv is trainable!\n",
      "block6d_expand_bn is trainable!\n",
      "block6d_expand_activation is trainable!\n",
      "block6d_dwconv is trainable!\n",
      "block6d_bn is trainable!\n",
      "block6d_activation is trainable!\n",
      "block6d_se_squeeze is trainable!\n",
      "block6d_se_reshape is trainable!\n",
      "block6d_se_reduce is trainable!\n",
      "block6d_se_expand is trainable!\n",
      "block6d_se_excite is trainable!\n",
      "block6d_project_conv is trainable!\n",
      "block6d_project_bn is trainable!\n",
      "block6d_drop is trainable!\n",
      "block6d_add is trainable!\n",
      "block6e_expand_conv is trainable!\n",
      "block6e_expand_bn is trainable!\n",
      "block6e_expand_activation is trainable!\n",
      "block6e_dwconv is trainable!\n",
      "block6e_bn is trainable!\n",
      "block6e_activation is trainable!\n",
      "block6e_se_squeeze is trainable!\n",
      "block6e_se_reshape is trainable!\n",
      "block6e_se_reduce is trainable!\n",
      "block6e_se_expand is trainable!\n",
      "block6e_se_excite is trainable!\n",
      "block6e_project_conv is trainable!\n",
      "block6e_project_bn is trainable!\n",
      "block6e_drop is trainable!\n",
      "block6e_add is trainable!\n",
      "block6f_expand_conv is trainable!\n",
      "block6f_expand_bn is trainable!\n",
      "block6f_expand_activation is trainable!\n",
      "block6f_dwconv is trainable!\n",
      "block6f_bn is trainable!\n",
      "block6f_activation is trainable!\n",
      "block6f_se_squeeze is trainable!\n",
      "block6f_se_reshape is trainable!\n",
      "block6f_se_reduce is trainable!\n",
      "block6f_se_expand is trainable!\n",
      "block6f_se_excite is trainable!\n",
      "block6f_project_conv is trainable!\n",
      "block6f_project_bn is trainable!\n",
      "block6f_drop is trainable!\n",
      "block6f_add is trainable!\n",
      "block6g_expand_conv is trainable!\n",
      "block6g_expand_bn is trainable!\n",
      "block6g_expand_activation is trainable!\n",
      "block6g_dwconv is trainable!\n",
      "block6g_bn is trainable!\n",
      "block6g_activation is trainable!\n",
      "block6g_se_squeeze is trainable!\n",
      "block6g_se_reshape is trainable!\n",
      "block6g_se_reduce is trainable!\n",
      "block6g_se_expand is trainable!\n",
      "block6g_se_excite is trainable!\n",
      "block6g_project_conv is trainable!\n",
      "block6g_project_bn is trainable!\n",
      "block6g_drop is trainable!\n",
      "block6g_add is trainable!\n",
      "block6h_expand_conv is trainable!\n",
      "block6h_expand_bn is trainable!\n",
      "block6h_expand_activation is trainable!\n",
      "block6h_dwconv is trainable!\n",
      "block6h_bn is trainable!\n",
      "block6h_activation is trainable!\n",
      "block6h_se_squeeze is trainable!\n",
      "block6h_se_reshape is trainable!\n",
      "block6h_se_reduce is trainable!\n",
      "block6h_se_expand is trainable!\n",
      "block6h_se_excite is trainable!\n",
      "block6h_project_conv is trainable!\n",
      "block6h_project_bn is trainable!\n",
      "block6h_drop is trainable!\n",
      "block6h_add is trainable!\n",
      "block6i_expand_conv is trainable!\n",
      "block6i_expand_bn is trainable!\n",
      "block6i_expand_activation is trainable!\n",
      "block6i_dwconv is trainable!\n",
      "block6i_bn is trainable!\n",
      "block6i_activation is trainable!\n",
      "block6i_se_squeeze is trainable!\n",
      "block6i_se_reshape is trainable!\n",
      "block6i_se_reduce is trainable!\n",
      "block6i_se_expand is trainable!\n",
      "block6i_se_excite is trainable!\n",
      "block6i_project_conv is trainable!\n",
      "block6i_project_bn is trainable!\n",
      "block6i_drop is trainable!\n",
      "block6i_add is trainable!\n",
      "block6j_expand_conv is trainable!\n",
      "block6j_expand_bn is trainable!\n",
      "block6j_expand_activation is trainable!\n",
      "block6j_dwconv is trainable!\n",
      "block6j_bn is trainable!\n",
      "block6j_activation is trainable!\n",
      "block6j_se_squeeze is trainable!\n",
      "block6j_se_reshape is trainable!\n",
      "block6j_se_reduce is trainable!\n",
      "block6j_se_expand is trainable!\n",
      "block6j_se_excite is trainable!\n",
      "block6j_project_conv is trainable!\n",
      "block6j_project_bn is trainable!\n",
      "block6j_drop is trainable!\n",
      "block6j_add is trainable!\n",
      "block6k_expand_conv is trainable!\n",
      "block6k_expand_bn is trainable!\n",
      "block6k_expand_activation is trainable!\n",
      "block6k_dwconv is trainable!\n",
      "block6k_bn is trainable!\n",
      "block6k_activation is trainable!\n",
      "block6k_se_squeeze is trainable!\n",
      "block6k_se_reshape is trainable!\n",
      "block6k_se_reduce is trainable!\n",
      "block6k_se_expand is trainable!\n",
      "block6k_se_excite is trainable!\n",
      "block6k_project_conv is trainable!\n",
      "block6k_project_bn is trainable!\n",
      "block6k_drop is trainable!\n",
      "block6k_add is trainable!\n",
      "block6l_expand_conv is trainable!\n",
      "block6l_expand_bn is trainable!\n",
      "block6l_expand_activation is trainable!\n",
      "block6l_dwconv is trainable!\n",
      "block6l_bn is trainable!\n",
      "block6l_activation is trainable!\n",
      "block6l_se_squeeze is trainable!\n",
      "block6l_se_reshape is trainable!\n",
      "block6l_se_reduce is trainable!\n",
      "block6l_se_expand is trainable!\n",
      "block6l_se_excite is trainable!\n",
      "block6l_project_conv is trainable!\n",
      "block6l_project_bn is trainable!\n",
      "block6l_drop is trainable!\n",
      "block6l_add is trainable!\n",
      "block6m_expand_conv is trainable!\n",
      "block6m_expand_bn is trainable!\n",
      "block6m_expand_activation is trainable!\n",
      "block6m_dwconv is trainable!\n",
      "block6m_bn is trainable!\n",
      "block6m_activation is trainable!\n",
      "block6m_se_squeeze is trainable!\n",
      "block6m_se_reshape is trainable!\n",
      "block6m_se_reduce is trainable!\n",
      "block6m_se_expand is trainable!\n",
      "block6m_se_excite is trainable!\n",
      "block6m_project_conv is trainable!\n",
      "block6m_project_bn is trainable!\n",
      "block6m_drop is trainable!\n",
      "block6m_add is trainable!\n",
      "top_conv is trainable!\n",
      "top_bn is trainable!\n",
      "top_activation is trainable!\n"
     ]
    }
   ],
   "source": [
    "#Let the model trainable from 'top' to 'block5'\n",
    "for layer in base_model.layers:\n",
    "\n",
    "    if 'block4' in layer.name:\n",
    "        layer.trainable = False\n",
    "   \n",
    "    if 'block5' in layer.name:\n",
    "        layer.trainable = True\n",
    "    \n",
    "    if layer.trainable:\n",
    "        print(layer.name , \"is trainable!\")\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-402.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-403.gamma\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-403.beta\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-404.depthwise_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-405.gamma\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-405.beta\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-406.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-406.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-407.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-407.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-408.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-409.gamma\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-409.beta\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-410.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-411.gamma\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-411.beta\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-412.depthwise_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-413.gamma\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-413.beta\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-414.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-414.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-415.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-415.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-416.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-417.gamma\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-417.beta\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-418.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-419.gamma\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-419.beta\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-420.depthwise_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-421.gamma\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-421.beta\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-422.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-422.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-423.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-423.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-424.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-425.gamma\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-425.beta\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-426.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-427.gamma\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-427.beta\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-428.depthwise_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-429.gamma\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-429.beta\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-430.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-430.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-431.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-431.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-432.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-433.gamma\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-433.beta\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-402.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-403.gamma\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-403.beta\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-404.depthwise_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-405.gamma\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-405.beta\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-406.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-406.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-407.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-407.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-408.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-409.gamma\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-409.beta\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-410.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-411.gamma\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-411.beta\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-412.depthwise_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-413.gamma\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-413.beta\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-414.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-414.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-415.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-415.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-416.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-417.gamma\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-417.beta\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-418.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-419.gamma\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-419.beta\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-420.depthwise_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-421.gamma\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-421.beta\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-422.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-422.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-423.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-423.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-424.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-425.gamma\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-425.beta\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-426.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-427.gamma\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-427.beta\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-428.depthwise_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-429.gamma\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-429.beta\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-430.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-430.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-431.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-431.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-432.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-433.gamma\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-433.beta\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 428 steps, validate for 74 steps\n",
      "Epoch 1/15\n",
      "INFO:tensorflow:batch_all_reduce: 304 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "INFO:tensorflow:batch_all_reduce: 304 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "428/428 [==============================] - 1150s 3s/step - loss: 8.1210 - accuracy: 0.5787 - val_loss: 7.8577 - val_accuracy: 0.6503\n",
      "Epoch 2/15\n",
      "428/428 [==============================] - 903s 2s/step - loss: 7.1473 - accuracy: 0.6049 - val_loss: 8.3195 - val_accuracy: 0.6123\n",
      "Epoch 3/15\n",
      "428/428 [==============================] - 897s 2s/step - loss: 5.8066 - accuracy: 0.6382 - val_loss: 7.2092 - val_accuracy: 0.6402\n",
      "Epoch 4/15\n",
      "428/428 [==============================] - 914s 2s/step - loss: 5.6532 - accuracy: 0.6478 - val_loss: 7.7305 - val_accuracy: 0.6562\n",
      "Epoch 5/15\n",
      "428/428 [==============================] - 909s 2s/step - loss: 5.1935 - accuracy: 0.6667 - val_loss: 7.1160 - val_accuracy: 0.6706\n",
      "Epoch 6/15\n",
      "428/428 [==============================] - 913s 2s/step - loss: 4.9714 - accuracy: 0.6750 - val_loss: 6.7529 - val_accuracy: 0.6867\n",
      "Epoch 7/15\n",
      "428/428 [==============================] - 913s 2s/step - loss: 4.7453 - accuracy: 0.6931 - val_loss: 6.8957 - val_accuracy: 0.6824\n",
      "Epoch 8/15\n",
      "428/428 [==============================] - 916s 2s/step - loss: 4.9120 - accuracy: 0.6934 - val_loss: 7.7736 - val_accuracy: 0.6453\n",
      "Epoch 9/15\n",
      "427/428 [============================>.] - ETA: 1s - loss: 4.5495 - accuracy: 0.7037\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 2.9999999242136255e-05.\n",
      "428/428 [==============================] - 904s 2s/step - loss: 4.5539 - accuracy: 0.7038 - val_loss: 7.6069 - val_accuracy: 0.6360\n",
      "Epoch 10/15\n",
      "428/428 [==============================] - 914s 2s/step - loss: 3.6607 - accuracy: 0.7333 - val_loss: 6.8397 - val_accuracy: 0.6731\n",
      "Epoch 11/15\n",
      "428/428 [==============================] - 912s 2s/step - loss: 3.4087 - accuracy: 0.7518 - val_loss: 6.8223 - val_accuracy: 0.6968\n",
      "Epoch 12/15\n",
      "428/428 [==============================] - 915s 2s/step - loss: 3.1432 - accuracy: 0.7594 - val_loss: 6.6522 - val_accuracy: 0.6959\n",
      "Epoch 13/15\n",
      "428/428 [==============================] - 915s 2s/step - loss: 3.2168 - accuracy: 0.7634 - val_loss: 6.5534 - val_accuracy: 0.6951\n",
      "Epoch 14/15\n",
      "428/428 [==============================] - 906s 2s/step - loss: 2.9788 - accuracy: 0.7753 - val_loss: 7.3741 - val_accuracy: 0.6740\n",
      "Epoch 15/15\n",
      "428/428 [==============================] - 913s 2s/step - loss: 2.8637 - accuracy: 0.7781 - val_loss: 6.0564 - val_accuracy: 0.7221\n"
     ]
    }
   ],
   "source": [
    "n_epoch = 15\n",
    "with my_strategy.scope():\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=tf.keras.optimizers.Nadam(learning_rate = 0.0001), # raise lr a bit\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    history_8 = model.fit_generator(generator=train_generator, steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                          validation_data=valid_generator, validation_steps=STEP_SIZE_VALID,\n",
    "                          epochs=n_epoch,\n",
    "                          shuffle=True,\n",
    "                          verbose=1,\n",
    "                          callbacks=[lr_scheduler,early_stopping_cb,tensorboard_cb],\n",
    "                          class_weight=CLASS_WEIGHT\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "with my_strategy.scope():\n",
    "\n",
    "    # Save or load the weights using the `checkpoint_path` format\n",
    "    model.save_weights(checkpoint_path.format(epoch=86))\n",
    "    #model.load_weights(checkpoint_path.format(epoch=86))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 398 images belonging to 50 classes.\n",
      "WARNING:tensorflow:From <ipython-input-40-39457cb5e2a0>:11: Model.evaluate_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.evaluate, which supports generators.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Prediction [Loss , accuracy] on test data = [0.26394664083264796, 0.7788945]\n"
     ]
    }
   ],
   "source": [
    "with my_strategy.scope():\n",
    "\n",
    "    test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "    test_generator = test_datagen.flow_from_directory(directory = test_dir,\n",
    "                                                  class_mode = 'categorical',\n",
    "                                                  target_size = train_input_shape[0:2],\n",
    "                                                  batch_size = 1,\n",
    "                                                  classes = artist_names)\n",
    "    STEP_SIZE_TEST = test_generator.n//test_generator.batch_size\n",
    "\n",
    "    score = model.evaluate_generator(test_generator, STEP_SIZE_TEST)\n",
    "    \n",
    "    print(\"Prediction [Loss , accuracy] on test data =\" , score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MyCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, patience = 5):\n",
    "        super(MyCallback, self).__init__()\n",
    "        self.patience = patience\n",
    "        self.best_weights = None\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        # The number of epoch it has waited when loss is no longer minimum.\n",
    "        self.wait = 0\n",
    "        # The epoch the training stops at.\n",
    "        self.stopped_epoch = 0\n",
    "        # Initialize the best as infinity.\n",
    "        self.best = np.Inf\n",
    "    def on_epoch_end(self, epoch , logs = {}):\n",
    "        current = logs.get('loss')\n",
    "        if np.less(current, self.best):\n",
    "            self.best = current\n",
    "            self.wait = 0\n",
    "            # Record the best weights if current results is better (less).\n",
    "            self.best_weights = self.model.get_weights()\n",
    "        else:\n",
    "            self.wait += 1\n",
    "            if self.wait >= self.patience:\n",
    "                self.stopped_epoch = epoch\n",
    "                self.model.stop_training = True\n",
    "                print('Restoring model weights from the end of the best epoch.')\n",
    "                self.model.set_weights(self.best_weights)\n",
    "         \n",
    "        if logs.get('val_acc') < log.get('acc') :\n",
    "                if logs.get('val_acc') < best_val_acc :\n",
    "                    self.patience -= 1\n",
    "                    if self.patience == 0:\n",
    "                        self.model.stop_training = True\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        if self.stopped_epoch > 0:\n",
    "            print('Epoch %05d: early stopping' % (self.stopped_epoch + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
